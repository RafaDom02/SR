{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2024 Pablo Castells y Alejandro Bellogín\n",
    "\n",
    "El código que contiene este notebook se ha implementado para la realización de las prácticas de la asignatura \"Sistemas de recomendación\" del Máster en Ciencia de Datos, impartido en la Escuela Politécnica Superior de la Universidad Autónoma de Madrid. El fin del mismo, así como su uso, se ciñe a las actividades docentes de dicha asignatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKBXprvhpqQr"
   },
   "source": [
    "### **Sistemas de recomendación 2024-25**\n",
    "### Universidad Autónoma de Madrid, Escuela Politécnica Superior\n",
    "### Máster en Ciencia de Datos\n",
    "\n",
    "# Filtrado colaborativo bilineal: similitud y factorización de matrices\n",
    "\n",
    "Fechas:\n",
    "\n",
    "* Comienzo: martes 4 de febrero.\n",
    "* Entrega: lunes 24 de febrero, 23:59.\n",
    "\n",
    "## Autores:\n",
    "* Rafael Domínguez Sáez\n",
    "* Iñigo Martínez Ciriza\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Esta práctica tiene por objetivo la implementación y evaluación eficiente de métodos (bi)lineales de recomendación mediante filtrado colaborativo. En este bloque se desarrollarán:\n",
    "\n",
    "* Algoritmos de filtrado colaborativo basados en similitud.\n",
    "* Algoritmos de filtrado colaborativo basados en la factorización de matrices.\n",
    "* Métricas de evaluación de sistemas de recomendación.\n",
    "\n",
    "## Material proporcionado\n",
    "\n",
    "Se proporcionan software y datos para la realización de la práctica:\n",
    "\n",
    "* Algunas estructuras de datos ya implementadas, para manejar datos de ratings la salida de los recomendadores.\n",
    "* Un esqueleto de clases y funciones donde el estudiante desarrollará sus implementaciones. \n",
    "  - Se proporciona una celda de prueba al final de este notebook que deberá funcionar con las implementaciones del estudiante.\n",
    "  - Junto a la celda de prueba en este mismo notebook, se muestra como referencia un ejemplo de salida generada con una implementación de los profesores.\n",
    "* Los siguientes conjuntos de datos de ratings por usuarios a items:\n",
    "  - Dos conjuntos de juguete para prueba y depuración: <ins>toy1.csv</ins> (se genera en Matrices.ipynb) y <ins>toy2.csv</ins> (proporcionado en el curso Moodle) con ratings ficticios.\n",
    "  - Un conjunto de datos reales de ratings a películas: *ml-1m.zip* disponible en la Web de [MovieLens](https://grouplens.org/datasets/movielens/1m). De los archivos disponibles, se utilizará sólamente <ins>ratings.dat</ins>, añadiéndole una cabecera `u::i::r::t`.\n",
    "  \n",
    "Los esqueletos de código que se proporcionan aquí son a modo de guía: el estudiante puede modificarlo todo libremente, siempre que la celda de prueba funcione correctamente **sin cambios**.\n",
    "\n",
    "La entrega consistirá en un fichero tipo *notebook* donde se incluirán todas las **implementaciones** solicitadas en cada ejercicio, así como una explicación de cada uno a modo de **memoria**.\n",
    "\n",
    "La celda de prueba deberá ejecutar sin errores a la primera con el código entregado por el estudiante (naturalmente con salvedad de los ejercicios que no se hayan implementado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Estructuras de datos: ratings y recomendaciones\n",
    "\n",
    "Se proporcionan:\n",
    "* Una clase Ratings que permite leer los datos de un fichero de texto, así como un método que genera dos particiones aleatorias de entrenamiento y test, para evaluar y comparar la efectividad de diferentes algoritmos de recomendación.\n",
    "* Una clase Recommender que se utilizará como clase padre en todos los recomendadores.\n",
    "* Una clase Recommendation para manejar la salida (rankings de items) de los recomendadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Ratings:\n",
    "    def __init__(self, file=None, sep=','):\n",
    "        if file:\n",
    "            data = pd.read_csv(file, delimiter=sep, engine='python')\n",
    "            u, i, r = data.columns[0:3]\n",
    "            data.r = 1\n",
    "            self.m = data.pivot(index=u, columns=i, values=r).fillna(0).to_numpy(dtype=np.float32)\n",
    "            self.uids = np.sort(data[u].unique())\n",
    "            self.iids = np.sort(data[i].unique())\n",
    "            self.uidxs = {u:j for j, u in enumerate(self.uids)}\n",
    "            self.iidxs = {i:j for j, i in enumerate(self.iids)}\n",
    "            self._nratings = (self.m > 0).sum()\n",
    "            self.data = data\n",
    "        \n",
    "    def copy(self, ratings, matrix):\n",
    "        self.m = matrix\n",
    "        self.uids = ratings.uids\n",
    "        self.iids = ratings.iids\n",
    "        self.uidxs = ratings.uidxs\n",
    "        self.iidxs = ratings.iidxs\n",
    "        self._nratings = (matrix > 0).sum()\n",
    "        return self\n",
    "    \n",
    "    def matrix(self):\n",
    "        return self.m\n",
    "    \n",
    "    def nusers(self):\n",
    "        return len(self.uids)\n",
    "    \n",
    "    def nitems(self):\n",
    "        return len(self.iids)\n",
    "    \n",
    "    # uidx can be an int or an array-like of ints.\n",
    "    def uidx_to_uid(self, uidx):\n",
    "        return self.uids[uidx]\n",
    "        \n",
    "    # iidx can be an int or an array-like of ints.\n",
    "    def iidx_to_iid(self, iidx):\n",
    "        return self.iids[iidx]\n",
    "    \n",
    "    def uid_to_uidx(self, uid):\n",
    "        return self.uidxs[uid]\n",
    "        \n",
    "    def iid_to_iidx(self, iid):\n",
    "        return self.iidxs[iid]\n",
    "        \n",
    "    def iidx_rated_by(self, uidx):\n",
    "        self.m[uidx].nonzero()\n",
    "        \n",
    "    def uidx_who_rated(self, iidx):\n",
    "        self.m[:, iidx].nonzero()\n",
    "        \n",
    "    def random_split(self, ratio):\n",
    "        mask = np.random.choice([True, False], size=self.m.shape, p=[ratio, 1-ratio])\n",
    "        train = self.m * mask\n",
    "        test = self.m * ~mask\n",
    "        return Ratings().copy(self, train), Ratings().copy(self, test)\n",
    "    \n",
    "    def sequence_split(self):\n",
    "        # self.data.columns = ['u', 'i', 'r', 't']\n",
    "        test_ids = [group.sort_values(by='t', ascending=False)[['u', 'i']].to_numpy()[0] \n",
    "                    for _, group in self.data.groupby(by='u')]\n",
    "        test_idx = np.array([[self.uid_to_uidx(uid), self.iid_to_iidx(iid)] for uid, iid in test_ids])\n",
    "        mask = np.ones(self.matrix().shape)\n",
    "        mask[test_idx[:, 0], test_idx[:, 1]] = 0\n",
    "        train = self.m * mask\n",
    "        test = self.m * (1-mask)\n",
    "        return Ratings().copy(self, train), Ratings().copy(self, test)\n",
    "    \n",
    "    #\n",
    "    # The remaining functions are just for debugging purposes.\n",
    "    #\n",
    "\n",
    "    def rating(self, uid, iid):\n",
    "        return self.matrix()[self.uid_to_uidx(uid), self.iid_to_iidx(iid)]\n",
    "\n",
    "    def items_rated_by(self, uid):\n",
    "        return self.iidx_to_iid(self.iidx_rated_by(self.uid_to_uidx(uid)))\n",
    "        \n",
    "    def users_who_rated(self, iid):\n",
    "        return self.uidx_to_uid(self.uidx_who_rated(self.iid_to_iidx(iid)))\n",
    "    \n",
    "    def user_ratings(self, uid):\n",
    "        iidxs = self.matrix()[self.uid_to_uidx(uid)].nonzero()[0]\n",
    "        return {self.iidx_to_iid(iidx): fround(r) for iidx, r in zip(iidxs, self.matrix()[self.uid_to_uidx(uid), iidxs])}\n",
    "\n",
    "    def item_ratings(self, iid):\n",
    "        uidxs = self.matrix()[:, self.iid_to_iidx(iid)].nonzero()[0]\n",
    "        return {self.uidx_to_uid(uidx): fround(r) for uidx, r in zip(uidxs, self.matrix()[uidxs, self.iid_to_iidx(iid)])}\n",
    "\n",
    "    def nratings(self):\n",
    "        return self._nratings\n",
    " \n",
    "    def save(self, file):\n",
    "        df = pd.DataFrame(columns=self.iids, index=self.uids, data=self.m).unstack().reset_index(name='r')\n",
    "        df.columns = ['i', 'u', 'r']\n",
    "        df = df[df.r>0][['u', 'i', 'r']].sort_values(by=['u', 'i'])\n",
    "        df.to_csv(file, index=False)\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "# Given a matrix, returns a matrix of positions of top k values per row.\n",
    "def top_positions_per_row(m, k):\n",
    "    return np.argpartition(m, -k)[:, -k:]\n",
    "\n",
    "class Recommendation:\n",
    "    def __init__(self, scores, n, training):\n",
    "        scores = scores * (training.matrix() == 0) # Don't recommend rated items.\n",
    "        # We sort the positions in top_iidx just in order to keep the NumPy tie break by original position \n",
    "        # (i.e. by ascending object ID) when we use this function later.\n",
    "        top_iidx = np.sort(top_positions_per_row(scores, min(n, training.nitems())))\n",
    "        # We sort by -scores because NumPy sorts by ascending and we want descending.\n",
    "        self.iidx_ranking = np.take_along_axis(top_iidx, np.argsort(-np.take_along_axis(scores, top_iidx, axis=1)), axis=1)\n",
    "        self.rank_scores = np.take_along_axis(scores, self.iidx_ranking, axis=1)\n",
    "        ranked_iids = training.iidx_to_iid(self.iidx_ranking)\n",
    "        self._recommendation = {training.uidx_to_uid(uidx) : [(iid, score) for iid, score in zip(ranked_iids[uidx], self.rank_scores[uidx]) if score > 0]\n",
    "                                for uidx in range(training.nusers())}\n",
    "\n",
    "    def ranked_iidx(self):\n",
    "        return self.iidx_ranking\n",
    "        \n",
    "    def recommendation(self, uid):\n",
    "        return self._recommendation[uid]\n",
    "        \n",
    "    # This function is for debuggind purposes.\n",
    "    # Format the recommendation as a string for the first n users. Trim scores to 4 decimal digits.\n",
    "    def display(self, n):\n",
    "        r = ''\n",
    "        for uid in islice(self._recommendation, n):\n",
    "            r += f'    User {uid} -> <' \n",
    "            for iid, score in self.recommendation(uid): \n",
    "                r += f'{iid}:{str(fround(score, 4))} '\n",
    "            r = (r[:-1] + '>\\n') if len(self.recommendation(uid)) > 0 else r + 'empty>\\n'\n",
    "        return r[:-1]\n",
    "        \n",
    "class Recommender():\n",
    "    def __init__(self, training):\n",
    "        self.training = training\n",
    "\n",
    "    def __repr__(self):\n",
    "        return type(self).__name__\n",
    "\n",
    "    def recommend(self, n):\n",
    "        return Recommendation(self.scores, n, self.training)\n",
    "\n",
    "# Just for pretty-printing numbers.\n",
    "def fround(x, n=20):\n",
    "    r = round(x)\n",
    "    rn = round(x, n)\n",
    "    return r if rn == r else rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Recomendación simple no personalizada\n",
    "\n",
    "La **salida** de un recomendador consistirá en un diccionario con un ránking por usuario. \n",
    "\n",
    "Implementar un primer **recomendador simple** por rating promedio en una clase `AverageRecommender`. El recomendador sólo recomendará items que tengan un mínimo número de ratings, que se indicará como parámetro en el constructor (con ello se mejora el acierto de la recomendación). Se proporciona una clase `MajorityRecommender` a modo de ejemplo en el que el estudiante podrá basarse, así como `RandomRecommender`, que se utiliza en ocasiones como referencia en experimentos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suggestion: compute the scores in each recommenders' constructor.\n",
    "\n",
    "class RandomRecommender(Recommender):\n",
    "    def __init__(self, training):\n",
    "        super().__init__(training)\n",
    "        self.scores = np.random.random(training.matrix().shape)\n",
    "\n",
    "class MajorityRecommender(Recommender):\n",
    "    def __init__(self, training, threshold=0):\n",
    "        super().__init__(training)\n",
    "        # training.matrix() >= threshold creates a mask with 'True' on relevant ratings and 'False' anywhere\n",
    "        # else. Thus 'pop' is an array with the counts of relevant ratings of each item.\n",
    "        pop = np.sum(training.matrix() >= threshold, axis=0)\n",
    "        # This product by a vector of ones (of user-row length) creates a matrix where the pop vector gets\n",
    "        # copied on all rows; the recommendation is not personalized and ranking is the same for all users \n",
    "        # -- except of course in the end different training items will be filtered out for different users.\n",
    "        self.scores = np.outer(np.ones(training.nusers()), pop)\n",
    "\n",
    "class AverageRecommender(Recommender):\n",
    "    def __init__(self, training, minr=0):\n",
    "\n",
    "        # Creamos una máscara para los items que han sido evaluados al menos minr veces\n",
    "        n_ratings = np.count_nonzero(training.matrix(), axis=0)\n",
    "        mask = n_ratings >= minr\n",
    "\n",
    "        # Aplicamos la máscara a la matriz de evaluaciones\n",
    "        mask_scores = (training.matrix() * mask)\n",
    "\n",
    "        # Contamos el número de evaluaciones evitando divisiones entre 0 marcando al menos 1 evaluación por item\n",
    "        n_ratings *= mask\n",
    "        n_ratings[n_ratings == 0] = 1\n",
    "\n",
    "        # Calculamos la evaluación como la media de todas las evaluaciones\n",
    "        self.scores = np.outer(np.ones(training.nusers()), np.sum(mask_scores, axis=0) / n_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3YGEGm7haop",
    "tags": []
   },
   "source": [
    "### Ejercicio 1 &ndash; Explicación/documentación\n",
    "\n",
    "El objetivo de la calse `Ratings` es la de poder implementar las opearciones vistas y estudiadas a una matriz de ratings. Sobre cada item $i$ perteneciente a un conjunto, un usuario $u$ puede asignar un rating (o evaluación) de dicho item tal que $r(u,i)$. Sin embargo, no todos los usuarios realizarán evaluaciones de todos los items. Así, para identificar estos usuarios e items, la clase utiliza las variables `uidx` (para los usuarios) y `iidx` (para los items). Así, cada evaluación dentro de la matriz de ratings $r(u,i)$ se puede localizar a partir de `ratings[uidx][iidx]`.\n",
    "\n",
    "El objetivo de la clase `Recommender` es la de crear recomendadores que, a partir de la información contenida en la matriz de ratings, realicen predicciones sobre items que resultan de interés a los usuarios. Para ello, se realizan recomendaciones a partir de los ratings estimados $\\hat{r}(u,i)$. Para conocer cómo de buena es una recomendación, se divide el conjunto de datos de la matriz de ratings en la parte de entrenamiento y en la parte de test.\n",
    "\n",
    "El recomendador que hemos aplicado en este ejercicio es el `AverageRecommender`, el cual basa sus recomendaciones en los ratings promedios para dicho item. Cuanto mayor sea el rating promedio de un item, más se recomendará dicho item a los usuarios. Así, para cada usuario las recomendaciones son idénticas, no hay ninguna personalizaión. Este recomendador además no recomienda items a los usuarios si ya los han puntuado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3ti8qGedgNB",
    "tags": []
   },
   "source": [
    "## Ejercicio 2: Recomendación basada en similitud &ndash; kNN\n",
    "\n",
    "Implementar un algoritmo de filtrado colaborativo mediante vecinos próximos orientado a usuarios por *similitud coseno* (sin normalizar por la suma de similitudes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wzZ-6OG0dvwX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineUserSimilarity:\n",
    "    def __init__(self, training):\n",
    "        # Calculamos la similitud de todos los usuarios consigo mismos\n",
    "        dots = np.dot(training.matrix(),training.matrix().T)\n",
    "\n",
    "        # Obtenemos el vector de módulos de cada usuario\n",
    "        mods = np.sqrt(dots.diagonal())\n",
    "        mods[mods==0] = 1\n",
    "        \n",
    "        # Creamos una matriz de similitud de cosenos entre usaurios\n",
    "        # La similitud entre un usuario y él mismo es 0\n",
    "        self.sim = (dots/mods).T/mods\n",
    "        np.fill_diagonal(self.sim,0)\n",
    "\n",
    "class UserKNNRecommender(Recommender):\n",
    "    def __init__(self, training, sim, k):\n",
    "        super().__init__(training)\n",
    "\n",
    "        # Obtenemos los k vecinos más cercanos de cada usuario\n",
    "        knn = top_positions_per_row(sim.sim_matrix(), k)\n",
    "\n",
    "        # Creamos una máscara para los k vecinos más cercanos con 1 si es vecino y 0 en caso contrario\n",
    "        mask = np.zeros_like(sim.sim_matrix())\n",
    "        mask[np.arange(mask.shape[0]), knn.T] = 1\n",
    "\n",
    "        # Creamos una máscara para la matriz de similitud\n",
    "        knn_sim = sim.sim_matrix() * mask\n",
    "\n",
    "        # Calculamos los scores de la recomendación kNN\n",
    "        self.scores = knn_sim@training.matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2 &ndash; Explicación/documentación\n",
    "\n",
    "Para realizar las estimaciones de ratings, utilizamos un método basado en similitud. Así, a un usuario se le recomendarán ítems que sus $k$ usuarios más similares hayan dado un rating alto.\n",
    "Para calcular esta similitud, se calcula el coseno entre dos usuarios de la matriz de ratings de entrenamiento. Este coseno mide el ángulo entre dos usuarios en un espacio de ratings, de forma que cuanto más cercano sea a 1 (el ángulo sea más cercano a 0), más similares serán estos dos usuarios.\n",
    "\n",
    "Además, consideramos que no es buena idea recomendar ítems a un usuario que ya han sido evaluados por este mismo usuario y como la similitud de un usuario consigo mismo es siempre 1, todas las diagonales de la matriz de similitud se ignoran para calcular los scores.\n",
    "\n",
    "Por tanto, el filtrado colaborativo usando kNN obtiene los scores de los $k$ usuarios con similitud más alta y calcula la recomendación tal que:\n",
    "\n",
    "$\\hat{r}(u,i) = \\sum_{v \\in V} sim(u,v) \\cdot r(v,i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Factorización de matrices\n",
    "\n",
    "Implementar filtrado colaborativo mediante factorización de matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import datetime, time\n",
    "\n",
    "def plot(train_losses, test_values=[], test_metrics=[]):\n",
    "    f = plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses, color='blue', linewidth=.7, label='Training MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training error')\n",
    "    ax = plt.gca().twinx()\n",
    "    for m, m_name, color in zip(test_values, test_metrics, ['tab:red', 'darkgreen', 'darkorange', 'darkviolet']):\n",
    "        ax.plot(range(len(m)), m, linewidth=.7, color=color, label=f'Test {m_name}')\n",
    "        plt.ylabel('Test metric')\n",
    "    f.legend(loc='center right', bbox_to_anchor=(0.85, 0.5))\n",
    "        \n",
    "def print_progress(rec, start, epoch, error, test_values, test_metrics):\n",
    "    output = f'\\rTraining MF --> Epochs: {epoch+1}  Training error: {error}  '\n",
    "    if test_metrics: output += 'Test metrics: ' \n",
    "    for values, metric in zip(test_values, test_metrics): \n",
    "        val = metric.compute(rec.recommend(metric.cutoff))\n",
    "        output += f'{metric} = {val}  '\n",
    "        values.append(val)\n",
    "    output += f' \\033[94m[{datetime.timedelta(seconds=round(time.time() - start))}]\\033[0m'\n",
    "    print(output, end='              ')\n",
    "        \n",
    "class MF(Recommender):\n",
    "    def __init__(self, training, dim=50, lrate=.001, nepochs=20, test_metrics=[]):\n",
    "        super().__init__(training)\n",
    "        p,q = self.train(dim, lrate, nepochs, test_metrics)\n",
    "        self.scores = self.predict(p,q)\n",
    "        \n",
    "    def predict(self, p, q):\n",
    "        return (p @ q.T)\n",
    "        \n",
    "    def train(self, dim, lrate, nepochs, test_metrics):\n",
    "        # 50x3\n",
    "        p = abs(np.random.normal(scale=1/self.training.nusers(), size=(self.training.nusers(), dim)))\n",
    "        # 10x3\n",
    "        q = abs(np.random.normal(scale=1/self.training.nitems(), size=(self.training.nitems(), dim)))\n",
    "        \n",
    "        train_errors, test_values = [], [[] for _ in test_metrics]\n",
    "        start = time.time()\n",
    "        for epoch in range(nepochs):\n",
    "            self.score = self.predict(p,q)\n",
    "            err = self.scores - self.training.matrix() #50x10\n",
    "            \n",
    "            p += lrate * (err @ q)   #50x10 @ 10x3 -> 50x3\n",
    "            q += lrate * (err.T @ p) #10x50 @ 50x3 -> 10x3\n",
    "\n",
    "            e = (err**2).mean()\n",
    "            train_errors.append(e)\n",
    "            print_progress(self, start, epoch, e, test_values, test_metrics)\n",
    "        print()\n",
    "        # Don't plot for small datasets.\n",
    "        if self.training.nratings() > 1000 : plot(train_errors, test_values, test_metrics)\n",
    "        return p, q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7xYd4hzhukr",
    "tags": []
   },
   "source": [
    "### Ejercicio 3 &ndash; Explicación/documentación\n",
    "\n",
    "También se pueden realizar recomendaciones a los usuarios representando tanto a los usuarios como a los ítems en función de un vector de características.\n",
    "\n",
    "Así, se utilizan espacios que puedan representar sus gustos y sean más efectivos que calcular la similitud entre usuarios con kNN. Por tanto, la recomendación pasa a definirse de forma mucho más sencilla tal que $\\hat{r}(u,i) = u \\cdot i$. El problema es encontrar la representación de los usuarios e ítems en este espacio de características.\n",
    "\n",
    "Para encontrar los parámetros del modelo que definen el espacio de características usaremos un entrenamiento basado en minimizar el error cuadrático medio $MSE=(r(u,i) - u \\cdot i)^2$ para cada usuario e ítem.\n",
    "Para ello, utilizamos las matrices $P$ de dimensión $|U|\\times k$ y $Q$ de dimensión $|I| \\times k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVzsIg0Zev7a",
    "tags": []
   },
   "source": [
    "## Ejercicio 4: Evaluación\n",
    "\n",
    "Se desarrollarán clases que permitan calcular métricas para evaluar y comparar el acierto de los recomendadores: se implementarán **precisión** y **recall**. \n",
    "\n",
    "Como resumen de este bloque, se incluirá una *tabla con los valores de las métricas* (dos columnas) más el tiempo de ejecución (una columna más) sobre todos los algoritmos implementados (filas), al menos para el conjunto de datos de <ins>MovieLens 1M</ins>. En el caso de ser capaces de procesar un conjunto de datos más grande, se documentará el tamaño en RAM de la matriz de ratings.\n",
    "\n",
    "<!-- Opcionalmente, se podrán implementar otras métricas a elección del estudiante (nDCG, etc.), cuya prueba se incluirá en la función `student_test()` del ejercicio 4 (\"ampliaciones\"). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VqSKneeSe2bN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Metric():\n",
    "    def __init__(self, cutoff):\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "    def __repr__(self):\n",
    "        return type(self).__name__ + ('@' + str(self.cutoff) if self.cutoff != np.inf else '')\n",
    "\n",
    "class Precision(Metric):\n",
    "    def __init__(self, test, cutoff=np.inf, threshold=1):\n",
    "        super().__init__(cutoff)\n",
    "        self.test = test\n",
    "        # Umbral para considerar un ítem como relevante\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def compute(self, recommendation):\n",
    "        # Obtenemos las primeras 'cutoff' recomendaciones\n",
    "        cutoff_recommendations = recommendation.ranked_iidx()[:, 0:self.cutoff]\n",
    "        \n",
    "        # Extraemos los scores y las etiquetas de relevancia de las recomendaciones\n",
    "        x = np.take_along_axis(recommendation.score_matrix(), cutoff_recommendations, axis=1)\n",
    "        y = np.take_along_axis(self.test.matrix(), cutoff_recommendations, axis=1)\n",
    "        \n",
    "        # Matriz donde un elemento es relevante si su score es >= 0 y su valor real supera el threshold\n",
    "        relevant_matrix = (x >= 0) * (y >= self.threshold)\n",
    "\n",
    "        # Calculamos la precisión como el promedio de ítems relevantes entre las recomendaciones\n",
    "        return (np.sum(relevant_matrix, axis=1) / self.cutoff).mean()\n",
    "\n",
    "class Recall(Metric):\n",
    "    def __init__(self, test, cutoff=np.inf, threshold=1):\n",
    "        super().__init__(cutoff)\n",
    "        self.threshold = threshold\n",
    "        # Calculamos el número total de ítems relevantes para cada usuario\n",
    "        self.relevant_item = np.sum(test.matrix() >= threshold, axis=1)\n",
    "        \n",
    "        # Evitamos división por cero en caso de que no haya ítems relevantes\n",
    "        self.relevant_item[self.relevant_item == 0] = 1\n",
    "\n",
    "    def compute(self, recommendation):\n",
    "        # Obtenemos las primeras 'cutoff' recomendaciones\n",
    "        cutoff_recommendations = recommendation.ranked_iidx()[:, 0:self.cutoff]\n",
    "        \n",
    "        # Extraemos los scores y las etiquetas de relevancia de las recomendaciones\n",
    "        x = np.take_along_axis(recommendation.score_matrix(), cutoff_recommendations, axis=1)\n",
    "        y = np.take_along_axis(self.test.matrix(), cutoff_recommendations, axis=1)\n",
    "        \n",
    "        # Matriz donde un elemento es relevante si su score es >= 0 y su valor real supera el threshold\n",
    "        relevant_matrix = (x >= 0) * (y >= self.threshold)\n",
    "\n",
    "        # Calculamos el recall como el número de ítems relevantes recuperados dividido por el número total de ítems relevantes\n",
    "        return (np.divide(np.sum(relevant_matrix, axis=1), self.relevant_item)).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJDzjUp-hwNZ",
    "tags": []
   },
   "source": [
    "### Ejercicio 4 &ndash; Explicación/documentación\n",
    "\n",
    "Para evaluar los algoritmos implementados, se pueden utilizar dos medidas que hemos visto en clase:\n",
    "\n",
    "* Precision: mide cuántos de los elementos recomendados son realmente relevantes sobre el número total de elementos.\n",
    "* Recall: mide cuántos de los elementos relevantes han sido recuperados en la recomendación sobre el número de elementos relevantes totales.\n",
    "\n",
    "La relevancia de un elemento se refiere a los propios ratings de los usuarios sobre los ítems. Los ítems con un ranting de usuario $r(u,i)$ superior a cierto threshold será considerado relevante y el resto se descartan.\n",
    "\n",
    "Para ambas métricas se utilizan las matrices `x` e `y` que son representaciones de las condiciones que se deben cumplir:\n",
    "\n",
    "* El conjunto de scores de cada usuario (hasta el número de elementos cutoff).\n",
    "* El conjunto de scores que cumplen con el threshold esperado.\n",
    "\n",
    "Ambas métricas se obtienen al operar sobre el resultado obtenido de multiplicar las matrices `x` e `y` y pasarán a contener valores binarios:\n",
    "\n",
    "* Precision: media de 1 por fila dividido por el cutoff.\n",
    "* Recall: media de 1 por fila dividido entre el número de ítems relevantes.\n",
    "\n",
    "Ahora vamos a estudiar los valores de estas métricas para los diferentes algoritmos que hemos implementado hasta ahora: `RandomRecommender`, `MajorityRecommender`, `AverageRecommender`, `UserKNNRecommender` y `MFRecommender`. Para ello, utilizaremos el dataset de MovieLens que contiene el rating de 1 millón de películas.\n",
    "\n",
    "Ejemplo de tabla de resumen:\n",
    "\n",
    "||Precision@K|Recall@K|Tiempo de ejecución\n",
    "|-|:-:|:-:|:-:\n",
    "|RandomRecommender|...|...|...\n",
    "|MajorityRecommender|...|...|...\n",
    "|AverageRecommender|...|...|...\n",
    "|UserKNNRecommender|...|...|...\n",
    "|MFRecommender|...|...|..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpXHr18Cdl2Q",
    "tags": []
   },
   "source": [
    "## Ejercicio 5: Ampliaciones\n",
    "\n",
    "* Implementar otra variante de kNN a elección del estudiante.\n",
    "* Probar otras funciones de pérdida en MF.\n",
    "* Crear una implementación de las estructuras de ratings con matrices dispersas, de forma que sea posible generar recomendaciones sobre conjuntos de datos más grandes, tales como [MovieLens 10M](https://grouplens.org/datasets/movielens/10m) y [MovieLens 25M](https://grouplens.org/datasets/movielens/25m).\n",
    "* Otra(s) idea(s) de ejercicio a propuesta del estudiante, consultando con el profesor.\n",
    "\n",
    "Para probar las implementaciones deberá completarse la función `student_test()` para ilustrar la ejecución de las variantes adicionales, y se incluirán las filas que correspondan en la tabla del apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOfT2yZGpMNi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineItemSimilarity:\n",
    "    def __init__(self, training):\n",
    "        # Calculamos la similitud de todos los ítems consigo mismos\n",
    "        dots = np.dot(training.matrix().T,training.matrix())\n",
    "\n",
    "        # Obtenemos el vector de módulos de cada ítem\n",
    "        mods = np.sqrt(dots.diagonal())\n",
    "        mods[mods==0] = 1\n",
    "\n",
    "        # Creamos una matriz de similitud de cosenos entre usaurios\n",
    "        # La similitud entre un usuario y él mismo es 0\n",
    "        self.sim = (dots/mods).T/mods\n",
    "        np.fill_diagonal(self.sim,0)\n",
    "\n",
    "    def sim_matrix(self):\n",
    "        return self.sim\n",
    "\n",
    "class ItemKNNRecommender(Recommender):\n",
    "    def __init__(self, training, sim, k):\n",
    "        super().__init__(training)\n",
    "\n",
    "        # Obtenemos los k vecinos más cercanos de cada usuario\n",
    "        knn = top_positions_per_row(sim.sim_matrix(), k)\n",
    "\n",
    "        # Creamos una máscara para los k vecinos más cercanos con 1 si es vecino y 0 en caso contrario\n",
    "        mask = np.zeros_like(sim.sim_matrix())\n",
    "        mask[np.arange(mask.shape[0]), knn.T] = 1\n",
    "\n",
    "        # Creamos una máscara para la matriz de similitud\n",
    "        knn_sim = sim.sim_matrix() * mask\n",
    "        \n",
    "        # Calculamos los scores de la recomendación kNN\n",
    "        self.scores = knn_sim@training.matrix()\n",
    "\n",
    "def student_test():\n",
    "    # Código de prueba aquí..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucORmwfCh4Um",
    "tags": []
   },
   "source": [
    "### Ejercicio 5 &ndash; Explicación/documentación\n",
    "\n",
    "Una alternativa a kNN basado en usuario es el kNN basado en ítems. Éste se calcula de forma sencilla trasponiendo la matriz con la que estamos trabajando. En lugar ahora de realizar recomendaciones de usuario basado en los ratings de otros usuarios similares, ahora la recomendación se basa en los propios ítems. Así, a un usuario que valore positivamente un ítem se le recomendará los ítems similares al que ha valorado, en lugar de los ítems de otro usuario similar a él.\n",
    "\n",
    "La similitud entre ítems se calcula de forma análoga a la similitud entre usuarios. Se utiliza el coseno del ángulo entre los vectores de ítems para estudiar los ítems más similares. Simplemente debemos invertir el orden de multiplicación de las matrices y trasponer las matrices correspondientes para obtener las dimensiones correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Celda de prueba\n",
    "\n",
    "Descarga los ficheros de datos y coloca sus contenidos en una carpeta **data** en el mismo directorio que este *notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Testing toy 1 dataset\n",
      "\u001b[34mReading the data at 08:53:07...\u001b[0m\n",
      "Ratings matrix takes 0.0 MB in RAM\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing the ratings data structures\n",
      "11 ratings by 4 users on 5 items\n",
      "Ratings of user v: {'b': 1, 'c': 1, 'd': 1}\n",
      "Ratings of item b: {'v': 1, 'x': 1, 'y': 1}\n",
      "-------------------------\n",
      "Testing RandomRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User v -> <a:0.9786 e:0.1183>\n",
      "    User x -> <c:0.9447 d:0.5218>\n",
      "    User y -> <d:0.5684 e:0.0188>\n",
      "    User z -> <e:0.6818 a:0.6176 c:0.6169 b:0.6121>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Recommendation' object has no attribute 'score_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 74\u001b[0m\n\u001b[0;32m     72\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=========================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTesting toy 1 dataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/toy1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_user\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_item\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=========================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTesting toy 2 dataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     76\u001b[0m test(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/toy2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, example_user\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, example_item\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, minr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, topn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[1;32mIn [9], line 17\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(ratings_file, example_user, example_item, k, minr, dim, topn, cutoff, threshold, sep)\u001b[0m\n\u001b[0;32m     15\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39mrandom_split(\u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m     16\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [Precision(test, cutoff\u001b[38;5;241m=\u001b[39mcutoff, threshold\u001b[38;5;241m=\u001b[39mthreshold), Recall(test, cutoff\u001b[38;5;241m=\u001b[39mcutoff, threshold\u001b[38;5;241m=\u001b[39mthreshold)]\n\u001b[1;32m---> 17\u001b[0m \u001b[43mrun_recommenders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [9], line 30\u001b[0m, in \u001b[0;36mrun_recommenders\u001b[1;34m(train, metrics, k, minr, dim, topn)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 30\u001b[0m \u001b[43mrun_recommender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRandomRecommender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m start \u001b[38;5;241m=\u001b[39m timer(start)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [9], line 65\u001b[0m, in \u001b[0;36mrun_recommender\u001b[1;34m(recommender, metrics, topn)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFour example recommendations:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m recommendation\u001b[38;5;241m.\u001b[39mdisplay(\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(metric, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecommendation\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn [7], line 18\u001b[0m, in \u001b[0;36mPrecision.compute\u001b[1;34m(self, recommendation)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, recommendation):\n\u001b[0;32m     16\u001b[0m     k_recommendations \u001b[38;5;241m=\u001b[39m recommendation\u001b[38;5;241m.\u001b[39mranked_iidx()[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcutoff]\n\u001b[1;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake_along_axis(\u001b[43mrecommendation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_matrix\u001b[49m(), k_recommendations, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     19\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake_along_axis(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mmatrix(), k_recommendations, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m     relevant_m \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Recommendation' object has no attribute 'score_matrix'"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "\n",
    "# Test data structures and algorithms on a dataset.\n",
    "def test(ratings_file, example_user, example_item, k, minr, dim, topn=np.inf, cutoff=np.inf, threshold=1, sep=','):\n",
    "    print(colored(f'Reading the data at ' + time.strftime('%X...'), 'blue'))\n",
    "    start = time.time()\n",
    "    ratings = Ratings(ratings_file, sep)\n",
    "    print(f'Ratings matrix takes {round(10 * ratings.matrix().nbytes / 1024 / 1024) / 10:,} MB in RAM')\n",
    "    timer(start)\n",
    "\n",
    "    # Test Ratings class on the dataset.\n",
    "    test_data(ratings, example_user, example_item)\n",
    "    \n",
    "    # Produce a rating split and test a set of recommenders. \n",
    "    train, test = ratings.random_split(0.8)\n",
    "    metrics = [Precision(test, cutoff=cutoff, threshold=threshold), Recall(test, cutoff=cutoff, threshold=threshold)]\n",
    "    run_recommenders(train, metrics, k, minr, dim, topn)\n",
    "\n",
    "# Test the rating data handling code (Ratings class).\n",
    "def test_data(ratings, example_user, example_item):\n",
    "    print('-------------------------\\nTesting the ratings data structures')\n",
    "    print(f'{ratings.nratings():,} ratings by {ratings.nusers():,} users on {ratings.nitems():,} items')\n",
    "    print(f'Ratings of user {example_user}: {ratings.user_ratings(example_user)}')\n",
    "    print(f'Ratings of item {example_item}: {ratings.item_ratings(example_item)}')\n",
    "\n",
    "# Run some recommenders on the some rating data as input - no evaluation.\n",
    "def run_recommenders(train, metrics, k, minr, dim, topn):\n",
    "    print('-------------------------')\n",
    "    start = time.time()\n",
    "    run_recommender(RandomRecommender(train), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    run_recommender(MajorityRecommender(train, threshold=1), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    run_recommender(AverageRecommender(train, minr), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    print('Creating user cosine similarity')\n",
    "    sim = CosineUserSimilarity(train)\n",
    "    start = timer(start)\n",
    "    print('Creating kNN recommender')\n",
    "    knn = UserKNNRecommender(train, sim, k)\n",
    "    start = timer(start)\n",
    "    run_recommender(knn, metrics, topn)\n",
    "    timer(start)\n",
    "\n",
    "    print('-------------------------')\n",
    "    start = time.time()\n",
    "    print('Creating MF recommender')\n",
    "    mf = MF(train, dim=dim, lrate=.0005, nepochs=150, test_metrics=metrics)\n",
    "    start = timer(start)\n",
    "    run_recommender(mf, metrics, topn)\n",
    "    timer(start)\n",
    "\n",
    "# Run a recommender and evaluate a list of metrics on its output.\n",
    "def run_recommender(recommender, metrics, topn):\n",
    "    print(f'Testing {recommender} (top {topn})')\n",
    "    recommendation = recommender.recommend(topn)\n",
    "    print('Four example recommendations:\\n' + recommendation.display(4))\n",
    "    for metric in metrics:\n",
    "        print(metric, '=', metric.compute(recommendation))\n",
    "\n",
    "from termcolor import colored\n",
    "def timer(start):\n",
    "    print(colored(f'--> elapsed time: {datetime.timedelta(seconds=round(time.time() - start))} <--', 'blue'))\n",
    "    return time.time()\n",
    "    \n",
    "np.random.seed(0)\n",
    "print('=========================\\nTesting toy 1 dataset')\n",
    "test('data/toy1.csv', example_user='v', example_item='b', k=4, minr=2, dim=5, topn=4, cutoff=4)\n",
    "print('=========================\\nTesting toy 2 dataset')\n",
    "test('data/toy2.csv', example_user=1, example_item=2, k=4, minr=2, dim=5, topn=4, cutoff=4)\n",
    "print('=========================\\nTesting MovieLens \\'1 million\\' dataset')\n",
    "test('data/ratings-1m.dat', example_user=200, example_item=1000, k=10, minr=3, dim=20, topn=10, cutoff=10, sep='::')\n",
    "print('=========================\\nDone.')\n",
    "\n",
    "# Additional testing?\n",
    "student_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salida obtenida por el estudiante\n",
    "\n",
    "*(por hacer)*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Enunciado P2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
