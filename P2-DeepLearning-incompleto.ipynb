{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2024 Pablo Castells y Alejandro Bellogín\n",
    "\n",
    "El código que contiene este notebook se ha implementado para la realización de las prácticas de la asignatura \"Sistemas de recomendación\" del Máster en Ciencia de Datos, impartido en la Escuela Politécnica Superior de la Universidad Autónoma de Madrid. El fin del mismo, así como su uso, se ciñe a las actividades docentes de dicha asignatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKBXprvhpqQr"
   },
   "source": [
    "### **Sistemas de recomendación 2024-25**\n",
    "### Universidad Autónoma de Madrid, Escuela Politécnica Superior\n",
    "### Máster en Ciencia de Datos\n",
    "\n",
    "# Filtrado colaborativo con aprendizaje profundo: EASE, Two-Tower, Transformers (EN CONSTRUCCIÓN)\n",
    "\n",
    "Fechas:\n",
    "\n",
    "* Comienzo: martes 25 de febrero.\n",
    "* Entrega: lunes 17 de marzo, 23:59.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Esta práctica tiene por objetivo comprender el diseño de métodos de filtrado colaborativo mediante deep learning como transición desde un modelo bilineal típico de factorización de matrices hacia modelos neuronales de complejidad arbitraria. En este bloque se desarrollarán:\n",
    "\n",
    "* Algoritmos de filtrado colaborativo basados en aprendizaje profundo.\n",
    "* Algoritmos de filtrado colaborativo orientados a datos secuenciales.\n",
    "* Métricas de evaluación de sistemas de recomendación.\n",
    "\n",
    "## Material proporcionado\n",
    "\n",
    "Al igual que en la P1, se proporcionan software y datos para la realización de la práctica:\n",
    "\n",
    "* Algunas estructuras de datos ya implementadas, para manejar datos de ratings y la salida de los recomendadores.\n",
    "* Un esqueleto de clases y funciones donde el estudiante desarrollará sus implementaciones. \n",
    "  - Se proporciona una celda de prueba al final de este notebook que deberá funcionar con las implementaciones del estudiante.\n",
    "  - Junto a la celda de prueba en este mismo notebook, se muestra como referencia un ejemplo de salida generada con una implementación de los profesores.\n",
    "* Los mismos conjuntos de datos de ratings que se usaban en la P1:\n",
    "  - Dos conjuntos de juguete para prueba y depuración: <ins>toy1.csv</ins> y <ins>toy2.csv</ins> con ratings ficticios.\n",
    "  - Un conjunto de datos reales de ratings a películas: *ml-1m.zip* disponible en la Web de [MovieLens](https://grouplens.org/datasets/movielens/1m). De los archivos disponibles, se utilizará sólamente <ins>ratings.dat</ins>, añadiéndole una cabecera `u::i::r::t`.\n",
    "  \n",
    "Los esqueletos de código que se proporcionan aquí son a modo de guía: el estudiante puede modificarlo todo libremente, siempre que la celda de prueba funcione correctamente **sin cambios**.\n",
    "\n",
    "En concreto, si para la P1 el estudiante ya hubiera hecho cambios en alguna de estas clases, puede continuar usando dichas modificaciones.\n",
    "\n",
    "La entrega consistirá en un fichero tipo *notebook* donde se incluirán todas las **implementaciones** solicitadas en cada ejercicio, así como una explicación de cada uno a modo de **memoria**.\n",
    "\n",
    "La celda de prueba deberá ejecutar sin errores a la primera con el código entregado por el estudiante (naturalmente con salvedad de los ejercicios que no se hayan implementado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Estructuras de datos: ratings y recomendaciones\n",
    "\n",
    "Se proporcionan:\n",
    "* Una clase Ratings que permite leer los datos de un fichero de texto, así como un método que genera dos particiones (de forma <b>aleatoria</b> o <b>temporal</b>) de entrenamiento y test, para evaluar y comparar la efectividad de diferentes algoritmos de recomendación.\n",
    "* Se pueden reutilizar las clases Recommender y Recommendation de la práctica anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Ratings:\n",
    "    def __init__(self, file=None, sep=','):\n",
    "        if file:\n",
    "            data = pd.read_csv(file, delimiter=sep, engine='python')\n",
    "            u, i, r, t = data.columns[0:4]\n",
    "            data.r = 1\n",
    "            self.m = data.pivot(index=u, columns=i, values=r).fillna(0).to_numpy(dtype=np.float32)\n",
    "            self.mt = data.pivot(index=u, columns=i, values=t).fillna(-1).to_numpy(dtype=np.float32)\n",
    "            self.uids = np.sort(data[u].unique())\n",
    "            self.iids = np.sort(data[i].unique())\n",
    "            self.uidxs = {u:j for j, u in enumerate(self.uids)}\n",
    "            self.iidxs = {i:j for j, i in enumerate(self.iids)}\n",
    "            self._nratings = (self.m > 0).sum()\n",
    "            self.data = data\n",
    "        \n",
    "    def copy(self, ratings, matrix, temp_matrix):\n",
    "        self.m = matrix\n",
    "        self.mt = temp_matrix\n",
    "        self.uids = ratings.uids\n",
    "        self.iids = ratings.iids\n",
    "        self.uidxs = ratings.uidxs\n",
    "        self.iidxs = ratings.iidxs\n",
    "        self._nratings = (matrix > 0).sum()\n",
    "        dfr = pd.DataFrame(columns=self.iids, index=self.uids, data=self.m).unstack().reset_index(name='r')\n",
    "        dfr.columns = ['i', 'u', 'r']\n",
    "        dft = pd.DataFrame(columns=self.iids, index=self.uids, data=self.mt).unstack().reset_index(name='t')\n",
    "        dft.columns = ['i', 'u', 't']\n",
    "        df_key = ['u','i']\n",
    "        df = pd.concat([dfr.set_index(df_key).squeeze(), dft.set_index(df_key).squeeze()], keys = ['r','t'],axis=1).fillna(0).reset_index()\n",
    "        self.data = df[df.r>0][['u', 'i', 'r', 't']].sort_values(by=['u', 'i'])\n",
    "        return self\n",
    "    \n",
    "    def matrix(self):\n",
    "        return self.m\n",
    "\n",
    "    def temporal_matrix(self):\n",
    "        return self.mt\n",
    "\n",
    "    def nusers(self):\n",
    "        return len(self.uids)\n",
    "    \n",
    "    def nitems(self):\n",
    "        return len(self.iids)\n",
    "    \n",
    "    # uidx can be an int or an array-like of ints.\n",
    "    def uidx_to_uid(self, uidx):\n",
    "        return self.uids[uidx]\n",
    "        \n",
    "    # iidx can be an int or an array-like of ints.\n",
    "    def iidx_to_iid(self, iidx):\n",
    "        return self.iids[iidx]\n",
    "    \n",
    "    def uid_to_uidx(self, uid):\n",
    "        return self.uidxs[uid]\n",
    "        \n",
    "    def iid_to_iidx(self, iid):\n",
    "        return self.iidxs[iid]\n",
    "        \n",
    "    def iidx_rated_by(self, uidx):\n",
    "        self.m[uidx].nonzero()\n",
    "        \n",
    "    def uidx_who_rated(self, iidx):\n",
    "        self.m[:, iidx].nonzero()\n",
    "        \n",
    "    def random_split(self, ratio):\n",
    "        mask = np.random.choice([True, False], size=self.m.shape, p=[ratio, 1-ratio])\n",
    "        train = self.m * mask\n",
    "        temp_train = self.mt * mask\n",
    "        test = self.m * ~mask\n",
    "        temp_test = self.mt * ~mask\n",
    "        return Ratings().copy(self, train, temp_train), Ratings().copy(self, test, temp_test)\n",
    "    \n",
    "    def peruser_sequence_split(self, ntestitems=1):\n",
    "        test_ids_arr = [group.sort_values(by='t', ascending=False)[['u', 'i']].to_numpy() \n",
    "                    for _, group in self.data.groupby(by='u')]\n",
    "        test_ids = []\n",
    "        for user_arr in test_ids_arr:\n",
    "            for ids in user_arr[:ntestitems]:\n",
    "                test_ids.append(ids)\n",
    "        #print(test_ids)\n",
    "        test_idx = np.array([[self.uid_to_uidx(uid), self.iid_to_iidx(iid)] for uid, iid in test_ids])\n",
    "        mask = np.ones(self.matrix().shape)\n",
    "        mask[test_idx[:, 0], test_idx[:, 1]] = 0\n",
    "        train = self.m * mask\n",
    "        temp_train = self.mt * mask\n",
    "        test = self.m * (1-mask)\n",
    "        temp_test = self.mt * (1-mask)\n",
    "        return Ratings().copy(self, train, temp_train), Ratings().copy(self, test, temp_test)\n",
    "    \n",
    "    #\n",
    "    # The remaining functions are just for debugging purposes.\n",
    "    #\n",
    "\n",
    "    def rating(self, uid, iid):\n",
    "        return self.matrix()[self.uid_to_uidx(uid), self.iid_to_iidx(iid)]\n",
    "\n",
    "    def items_rated_by(self, uid):\n",
    "        return self.iidx_to_iid(self.iidx_rated_by(self.uid_to_uidx(uid)))\n",
    "        \n",
    "    def users_who_rated(self, iid):\n",
    "        return self.uidx_to_uid(self.uidx_who_rated(self.iid_to_iidx(iid)))\n",
    "    \n",
    "    def user_ratings(self, uid):\n",
    "        iidxs = self.matrix()[self.uid_to_uidx(uid)].nonzero()[0]\n",
    "        return {self.iidx_to_iid(iidx): fround(r) for iidx, r in zip(iidxs, self.matrix()[self.uid_to_uidx(uid), iidxs])}\n",
    "\n",
    "    def item_ratings(self, iid):\n",
    "        uidxs = self.matrix()[:, self.iid_to_iidx(iid)].nonzero()[0]\n",
    "        return {self.uidx_to_uid(uidx): fround(r) for uidx, r in zip(uidxs, self.matrix()[uidxs, self.iid_to_iidx(iid)])}\n",
    "\n",
    "    def nratings(self):\n",
    "        return self._nratings\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: EASE\n",
    "\n",
    "Implementar un modelo de filtrado colaborativo lineal basado en autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ease(Recommender):\n",
    "    def __init__(self, training, l=20, threshold=3):\n",
    "        super().__init__(training)\n",
    "        # Your code here...\n",
    "\n",
    "        self.scores = # Your code here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Factorización de matrices: modelo deep learning\n",
    "\n",
    "Como alternativa a la implementación realizada en la P1 del modelo de factorización de matrices, en esta práctica vas a reformular esa implementación como un caso particular \"degenerado\" de arquitectura neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación en TensorFlow\n",
    "\n",
    "Completar los huecos marcados con `# Your code here...`.\n",
    "\n",
    "Observaciones:\n",
    "* Por la estructura de datos de entrenamiento que maneja TensorFlow, entrenar con toda la matriz de ratings (incluyendo todas las celdas sin dato) es demasiado costoso. Por ello se tomará una muestra pequeña de ejemplos negativos en cada época.\n",
    "* En el esqueleto que aquí se proporciona, no se genera la traza (curva) de P@10 durante el entrenamiento ya que no encaja fácilmente en el API Keras de TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm.keras import TqdmCallback\n",
    "import time, datetime\n",
    "\n",
    "class DLMFRecommender(Recommender):\n",
    "    def __init__(self, training, k=50, lrate=0.01, nepochs=150, neg=4):\n",
    "        super().__init__(training)\n",
    "        # Create the model - this will directly trigger training.        \n",
    "        tf.random.set_seed(0) # For comparability and debugging (the randomness here is in parameter initialization).\n",
    "        self.model, self.hist = self.create_model(training, k, lrate, neg, nepochs)\n",
    "        # Plot the training error and report the final test metric value (P@10).\n",
    "        # Your code here...\n",
    "\n",
    "        uexplode = np.full((training.nitems(), training.nusers()), np.arange(training.nusers())).T.flatten()\n",
    "        iexplode = np.full((training.nusers(), training.nitems()), np.arange(training.nitems())).flatten()\n",
    "        self.scores = self.model.predict([uexplode, iexplode], batch_size=training.nusers()*100, \n",
    "                            verbose=1).reshape(training.nusers(), training.nitems())\n",
    "\n",
    "    def create_model(self, ratings, k, lrate, neg, nepochs):\n",
    "        # 'users' is an input layer of type tf.int64.\n",
    "        users = # Your code here...\n",
    "        user_embeddings = # Your code here...\n",
    "        # 'items' is an input layer of type tf.int64.\n",
    "        items = # Your code here...\n",
    "        item_embeddings = # Your code here...\n",
    "        # TensorFlow has a built-in dot-product layer.\n",
    "        dot = # Your code here...\n",
    "        # Now we need a generic model that wraps up the \"network\", specifying the input and output layers.\n",
    "        model = # Your code here...\n",
    "\n",
    "        # Compile the model: Adam optimizer is suggested here over SGD.\n",
    "        # Your code here...\n",
    "\n",
    "        # Show the model topology\n",
    "        model.summary()\n",
    "        tf.keras.utils.plot_model(model, show_shapes=True, dpi=150)\n",
    "        \n",
    "        hist = self.train_model(ratings, model, neg, nepochs)\n",
    "        return model, hist\n",
    "\n",
    "    def train_model(self, ratings, tf_mf, neg, nepochs):\n",
    "        # We inject 'neg' negative samples for every available rating in the training data\n",
    "        nneg = neg * ratings.nratings()\n",
    "        user_ids = np.concatenate(([ratings.uid_to_uidx(u) for u in ratings.data.u], np.random.choice(list(ratings.uidxs.values()), size=nneg)))\n",
    "        item_ids = np.concatenate(([ratings.iid_to_iidx(u) for u in ratings.data.i], np.random.choice(list(ratings.iidxs.values()), size=nneg)))\n",
    "        rs = ratings.matrix()[user_ids, item_ids]\n",
    "        batch_size = ratings.nratings() + nneg # Single batch with all the data at once.\n",
    "        \n",
    "        # Your code here... to actually do the training\n",
    "        hist = # Your code here...\n",
    "            , callbacks=[TqdmCallback(verbose=0)]) # Produces a prettier progress bar.\n",
    "        return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3YGEGm7haop",
    "tags": []
   },
   "source": [
    "### Ejercicio 2 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3ti8qGedgNB",
    "tags": []
   },
   "source": [
    "## Ejercicio 3: Implementación modelo Two-Tower\n",
    "\n",
    "Implementar tu propia versión de un modelo Two-Tower a partir de la arquitectura implementada de MF en el ejercicio anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzZ-6OG0dvwX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TwoTowerRecommender(DLMFRecommender):\n",
    "    # Your code here... Puede no ser necesario re-implementar todos los métodos..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVzsIg0Zev7a",
    "tags": []
   },
   "source": [
    "## Ejercicio 4: Recomendación secuencial [PENDIENTE]\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJDzjUp-hwNZ",
    "tags": []
   },
   "source": [
    "### Ejercicio 4 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpXHr18Cdl2Q",
    "tags": []
   },
   "source": [
    "## Ejercicio 5: Ampliaciones\n",
    "\n",
    "Explorar variaciones sobre una o varias de las implementaciones anteriores, tales como:\n",
    "\n",
    "* En general:\n",
    "    * Además de las métricas de evaluación usadas en la P1 (precision, recall) incluir otras métricas, bien de acierto (NDCG) u otras (cobertura, diversidad, etc.)\n",
    "\n",
    "* Sobre el ejercicio 1 (algoritmo EASE):\n",
    "    * Añadir la opción de asignar 0 a los pesos negativos, comprobando que su eficacia disminuye (como indica el artículo original)\n",
    "\n",
    "* Sobre el ejercicio 2 (factorización de matrices por aprendizaje profundo) y 3 (modelo Two-Tower):\n",
    "    * Diferentes funciones de scoring pérdida: sigmoide / BCE loss, BCE loss with logits.\n",
    "    * Diferentes optimizadores y configuraciones de los mismos (SGD, Adam, etc.).\n",
    "    * Variaciones en los hiperparámetros y configuración del modelo: learning rate, número de factores k, número de épocas, inicialización de parámetros del modelo, etc.\n",
    "    * Añadir opciones tales como regularización, dropout, etc.\n",
    "    * Añadir capas ocultas en la implementación sobre framework de deep learning.\n",
    "    * Explorar una formulación *pairwise learning to rank* sobre MF (p.e., BPR).\n",
    "\n",
    "* Sobre el ejercicio 4 (recomendación secuencial):\n",
    "    * ...\n",
    "    * ...\n",
    "    * ...\n",
    "\n",
    "Idealmente estas variaciones buscan mejorar la precisión de la recomendación, pero se valorarán intentos interesantes aunque resulten fallidos en ese aspecto.\n",
    "\n",
    "Para probar las implementaciones deberá completarse la función `student_test()` para ilustrar la ejecución de las variantes adicionales, y se incluirán las filas que correspondan en la tabla del apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOfT2yZGpMNi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Código aquí: clases, funciones...\n",
    "\n",
    "def student_test():\n",
    "    # Código de prueba aquí..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucORmwfCh4Um",
    "tags": []
   },
   "source": [
    "### Ejercicio 5 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Enunciado P2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
