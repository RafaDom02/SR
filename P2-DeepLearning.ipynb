{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2024 Pablo Castells y Alejandro Bellogín\n",
    "\n",
    "El código que contiene este notebook se ha implementado para la realización de las prácticas de la asignatura \"Sistemas de recomendación\" del Máster en Ciencia de Datos, impartido en la Escuela Politécnica Superior de la Universidad Autónoma de Madrid. El fin del mismo, así como su uso, se ciñe a las actividades docentes de dicha asignatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKBXprvhpqQr"
   },
   "source": [
    "### **Sistemas de recomendación 2024-25**\n",
    "### Universidad Autónoma de Madrid, Escuela Politécnica Superior\n",
    "### Máster en Ciencia de Datos\n",
    "\n",
    "# Filtrado colaborativo con aprendizaje profundo: EASE, Two-Tower, Transformers\n",
    "\n",
    "Fechas:\n",
    "\n",
    "* Comienzo: martes 25 de febrero.\n",
    "* Entrega: lunes 17 de marzo, 23:59.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Esta práctica tiene por objetivo comprender el diseño de métodos de filtrado colaborativo mediante deep learning como transición desde un modelo bilineal típico de factorización de matrices hacia modelos neuronales de complejidad arbitraria. En este bloque se desarrollarán:\n",
    "\n",
    "* Algoritmos de filtrado colaborativo basados en aprendizaje profundo.\n",
    "* Algoritmos de filtrado colaborativo orientados a datos secuenciales.\n",
    "* Métricas de evaluación de sistemas de recomendación.\n",
    "\n",
    "## Material proporcionado\n",
    "\n",
    "Al igual que en la P1, se proporcionan software y datos para la realización de la práctica:\n",
    "\n",
    "* Algunas estructuras de datos ya implementadas, para manejar datos de ratings y la salida de los recomendadores.\n",
    "* Un esqueleto de clases y funciones donde el estudiante desarrollará sus implementaciones. \n",
    "  - Se proporciona una celda de prueba al final de este notebook que deberá funcionar con las implementaciones del estudiante.\n",
    "  - Junto a la celda de prueba en este mismo notebook, se muestra como referencia un ejemplo de salida generada con una implementación de los profesores.\n",
    "* Los mismos conjuntos de datos de ratings que se usaban en la P1:\n",
    "  - Dos conjuntos de juguete para prueba y depuración: <ins>toy1.csv</ins> y <ins>toy2.csv</ins> con ratings ficticios.\n",
    "  - Un conjunto de datos reales de ratings a películas: *ml-1m.zip* disponible en la Web de [MovieLens](https://grouplens.org/datasets/movielens/1m). De los archivos disponibles, se utilizará sólamente <ins>ratings.dat</ins>, añadiéndole una cabecera `u::i::r::t`.\n",
    "  \n",
    "Los esqueletos de código que se proporcionan aquí son a modo de guía: el estudiante puede modificarlo todo libremente, siempre que la celda de prueba funcione correctamente **sin cambios**.\n",
    "\n",
    "En concreto, si para la P1 el estudiante ya hubiera hecho cambios en alguna de estas clases, puede continuar usando dichas modificaciones.\n",
    "\n",
    "La entrega consistirá en un fichero tipo *notebook* donde se incluirán todas las **implementaciones** solicitadas en cada ejercicio, así como una explicación de cada uno a modo de **memoria**.\n",
    "\n",
    "La celda de prueba deberá ejecutar sin errores a la primera con el código entregado por el estudiante (naturalmente con salvedad de los ejercicios que no se hayan implementado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Estructuras de datos: ratings y recomendaciones\n",
    "\n",
    "Se proporcionan:\n",
    "* Una clase Ratings que permite leer los datos de un fichero de texto, así como un método que genera dos particiones (de forma <b>aleatoria</b> o <b>temporal</b>) de entrenamiento y test, para evaluar y comparar la efectividad de diferentes algoritmos de recomendación.\n",
    "* Se pueden reutilizar las clases Recommender y Recommendation de la práctica anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Ratings:\n",
    "    def __init__(self, file=None, sep=','):\n",
    "        if file:\n",
    "            data = pd.read_csv(file, delimiter=sep, engine='python')\n",
    "            u, i, r, t = data.columns[0:4]\n",
    "            data.r = 1\n",
    "            self.m = data.pivot(index=u, columns=i, values=r).fillna(0).to_numpy(dtype=np.float32)\n",
    "            self.mt = data.pivot(index=u, columns=i, values=t).fillna(-1).to_numpy(dtype=np.float32)\n",
    "            self.uids = np.sort(data[u].unique())\n",
    "            self.iids = np.sort(data[i].unique())\n",
    "            self.uidxs = {u:j for j, u in enumerate(self.uids)}\n",
    "            self.iidxs = {i:j for j, i in enumerate(self.iids)}\n",
    "            self._nratings = (self.m > 0).sum()\n",
    "            self.data = data\n",
    "        \n",
    "    def copy(self, ratings, matrix, temp_matrix):\n",
    "        self.m = matrix\n",
    "        self.mt = temp_matrix\n",
    "        self.uids = ratings.uids\n",
    "        self.iids = ratings.iids\n",
    "        self.uidxs = ratings.uidxs\n",
    "        self.iidxs = ratings.iidxs\n",
    "        self._nratings = (matrix > 0).sum()\n",
    "        dfr = pd.DataFrame(columns=self.iids, index=self.uids, data=self.m).unstack().reset_index(name='r')\n",
    "        dfr.columns = ['i', 'u', 'r']\n",
    "        dft = pd.DataFrame(columns=self.iids, index=self.uids, data=self.mt).unstack().reset_index(name='t')\n",
    "        dft.columns = ['i', 'u', 't']\n",
    "        df_key = ['u','i']\n",
    "        df = pd.concat([dfr.set_index(df_key).squeeze(), dft.set_index(df_key).squeeze()], keys = ['r','t'],axis=1).fillna(0).reset_index()\n",
    "        self.data = df[df.r>0][['u', 'i', 'r', 't']].sort_values(by=['u', 'i'])\n",
    "        return self\n",
    "    \n",
    "    def matrix(self):\n",
    "        return self.m\n",
    "\n",
    "    def temporal_matrix(self):\n",
    "        return self.mt\n",
    "\n",
    "    def nusers(self):\n",
    "        return len(self.uids)\n",
    "    \n",
    "    def nitems(self):\n",
    "        return len(self.iids)\n",
    "    \n",
    "    # uidx can be an int or an array-like of ints.\n",
    "    def uidx_to_uid(self, uidx):\n",
    "        return self.uids[uidx]\n",
    "        \n",
    "    # iidx can be an int or an array-like of ints.\n",
    "    def iidx_to_iid(self, iidx):\n",
    "        return self.iids[iidx]\n",
    "    \n",
    "    def uid_to_uidx(self, uid):\n",
    "        return self.uidxs[uid]\n",
    "        \n",
    "    def iid_to_iidx(self, iid):\n",
    "        return self.iidxs[iid]\n",
    "        \n",
    "    def iidx_rated_by(self, uidx):\n",
    "        self.m[uidx].nonzero()\n",
    "        \n",
    "    def uidx_who_rated(self, iidx):\n",
    "        self.m[:, iidx].nonzero()\n",
    "        \n",
    "    def random_split(self, ratio):\n",
    "        mask = np.random.choice([True, False], size=self.m.shape, p=[ratio, 1-ratio])\n",
    "        train = self.m * mask\n",
    "        temp_train = self.mt * mask\n",
    "        test = self.m * ~mask\n",
    "        temp_test = self.mt * ~mask\n",
    "        return Ratings().copy(self, train, temp_train), Ratings().copy(self, test, temp_test)\n",
    "    \n",
    "    def peruser_sequence_split(self, ntestitems=1):\n",
    "        test_ids_arr = [group.sort_values(by='t', ascending=False)[['u', 'i']].to_numpy() \n",
    "                    for _, group in self.data.groupby(by='u')]\n",
    "        test_ids = []\n",
    "        for user_arr in test_ids_arr:\n",
    "            for ids in user_arr[:ntestitems]:\n",
    "                test_ids.append(ids)\n",
    "        #print(test_ids)\n",
    "        test_idx = np.array([[self.uid_to_uidx(uid), self.iid_to_iidx(iid)] for uid, iid in test_ids])\n",
    "        mask = np.ones(self.matrix().shape)\n",
    "        mask[test_idx[:, 0], test_idx[:, 1]] = 0\n",
    "        train = self.m * mask\n",
    "        temp_train = self.mt * mask\n",
    "        test = self.m * (1-mask)\n",
    "        temp_test = self.mt * (1-mask)\n",
    "        return Ratings().copy(self, train, temp_train), Ratings().copy(self, test, temp_test)\n",
    "    \n",
    "    #\n",
    "    # The remaining functions are just for debugging purposes.\n",
    "    #\n",
    "\n",
    "    def rating(self, uid, iid):\n",
    "        return self.matrix()[self.uid_to_uidx(uid), self.iid_to_iidx(iid)]\n",
    "\n",
    "    def items_rated_by(self, uid):\n",
    "        return self.iidx_to_iid(self.iidx_rated_by(self.uid_to_uidx(uid)))\n",
    "        \n",
    "    def users_who_rated(self, iid):\n",
    "        return self.uidx_to_uid(self.uidx_who_rated(self.iid_to_iidx(iid)))\n",
    "    \n",
    "    def user_ratings(self, uid):\n",
    "        iidxs = self.matrix()[self.uid_to_uidx(uid)].nonzero()[0]\n",
    "        return {self.iidx_to_iid(iidx): fround(r) for iidx, r in zip(iidxs, self.matrix()[self.uid_to_uidx(uid), iidxs])}\n",
    "\n",
    "    def item_ratings(self, iid):\n",
    "        uidxs = self.matrix()[:, self.iid_to_iidx(iid)].nonzero()[0]\n",
    "        return {self.uidx_to_uid(uidx): fround(r) for uidx, r in zip(uidxs, self.matrix()[uidxs, self.iid_to_iidx(iid)])}\n",
    "\n",
    "    def nratings(self):\n",
    "        return self._nratings\n",
    "    \n",
    "from itertools import islice\n",
    "\n",
    "# Given a matrix, returns a matrix of positions of top k values per row.\n",
    "def top_positions_per_row(m, k):\n",
    "    return np.argpartition(m, -k)[:, -k:]\n",
    "\n",
    "class Recommendation:\n",
    "    def __init__(self, scores, n, training):\n",
    "        scores = scores * (training.matrix() == 0) # Don't recommend rated items.\n",
    "        # We sort the positions in top_iidx just in order to keep the NumPy tie break by original position \n",
    "        # (i.e. by ascending object ID) when we use this function later.\n",
    "        top_iidx = np.sort(top_positions_per_row(scores, min(n, training.nitems())))\n",
    "        # We sort by -scores because NumPy sorts by ascending and we want descending.\n",
    "        self.iidx_ranking = np.take_along_axis(top_iidx, np.argsort(-np.take_along_axis(scores, top_iidx, axis=1)), axis=1)\n",
    "        self.rank_scores = np.take_along_axis(scores, self.iidx_ranking, axis=1)\n",
    "        ranked_iids = training.iidx_to_iid(self.iidx_ranking)\n",
    "        self._recommendation = {training.uidx_to_uid(uidx) : [(iid, score) for iid, score in zip(ranked_iids[uidx], self.rank_scores[uidx]) if score > 0]\n",
    "                                for uidx in range(training.nusers())}\n",
    "\n",
    "    def ranked_iidx(self):\n",
    "        return self.iidx_ranking\n",
    "        \n",
    "    def recommendation(self, uid):\n",
    "        return self._recommendation[uid]\n",
    "        \n",
    "    # This function is for debuggind purposes.\n",
    "    # Format the recommendation as a string for the first n users. Trim scores to 4 decimal digits.\n",
    "    def display(self, n):\n",
    "        r = ''\n",
    "        for uid in islice(self._recommendation, n):\n",
    "            r += f'    User {uid} -> <' \n",
    "            for iid, score in self.recommendation(uid): \n",
    "                r += f'{iid}:{str(fround(score, 4))} '\n",
    "            r = (r[:-1] + '>\\n') if len(self.recommendation(uid)) > 0 else r + 'empty>\\n'\n",
    "        return r[:-1]\n",
    "    \n",
    "class Recommender():\n",
    "    def __init__(self, training):\n",
    "        self.training = training\n",
    "\n",
    "    def __repr__(self):\n",
    "        return type(self).__name__\n",
    "\n",
    "    def recommend(self, n):\n",
    "        return Recommendation(self.scores, n, self.training)\n",
    "\n",
    "# Just for pretty-printing numbers.\n",
    "def fround(x, n=20):\n",
    "    r = round(x)\n",
    "    rn = round(x, n)\n",
    "    return r if rn == r else rn\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: EASE\n",
    "\n",
    "Implementar un modelo de filtrado colaborativo lineal basado en autoencoders.\n",
    "\n",
    "Observación: el parámetro _threshold_ indica a partir de qué valor se binariza la matriz de entrada, es decir, qué valores se consideran como positivos o negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ease(Recommender):\n",
    "    def __init__(self, training, l=20, threshold=3):\n",
    "        super().__init__(training)\n",
    "        X = training.matrix()\n",
    "        \n",
    "        # Aplicar el umbral: convierte en 0 las interacciones con valores < threshold\n",
    "        X = np.where(X >= threshold, X, 0)\n",
    "        \n",
    "        G = X.T @ X  # Matriz de covarianza\n",
    "        diag_indices = np.diag_indices_from(G)\n",
    "        G[diag_indices] += l  # Regularización L2\n",
    "        \n",
    "        P = np.linalg.inv(G)  # Inversa de la matriz regularizada\n",
    "        B = -P / np.diag(P)[:, None]  # Obtención de los pesos del modelo\n",
    "        B[diag_indices] = 0  # Evitar la auto-referencia en la predicción\n",
    "        \n",
    "        self.scores = X @ B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Factorización de matrices: modelo deep learning\n",
    "\n",
    "Como alternativa a la implementación realizada en la P1 del modelo de factorización de matrices, en esta práctica vas a reformular esa implementación como un caso particular \"degenerado\" de arquitectura neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación en TensorFlow\n",
    "\n",
    "Completar los huecos marcados con `# Your code here...`.\n",
    "\n",
    "Observaciones:\n",
    "* Por la estructura de datos de entrenamiento que maneja TensorFlow, entrenar con toda la matriz de ratings (incluyendo todas las celdas sin dato) es demasiado costoso. Por ello se tomará una muestra pequeña de ejemplos negativos en cada época.\n",
    "* En el esqueleto que aquí se proporciona, no se genera la traza (curva) de P@10 durante el entrenamiento ya que no encaja fácilmente en el API Keras de TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Master\\SR\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm.keras import TqdmCallback\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DLMFRecommender(Recommender):\n",
    "    def __init__(self, training, k=50, lrate=0.01, nepochs=150, neg=4):\n",
    "        super().__init__(training)\n",
    "        # Create the model - this will directly trigger training.        \n",
    "        tf.random.set_seed(0) # For comparability and debugging (the randomness here is in parameter initialization).\n",
    "        self.model, self.hist = self.create_model(training, k, lrate, neg, nepochs)\n",
    "        # Plot the training error and report the final test metric value (P@10).\n",
    "        # Your code here...\n",
    "        plt.figure()\n",
    "        plt.plot(self.hist.history['loss'])\n",
    "        plt.title('Training Error')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss (MSE)')\n",
    "        plt.show()\n",
    "\n",
    "        uexplode = np.full((training.nitems(), training.nusers()), np.arange(training.nusers())).T.flatten()\n",
    "        iexplode = np.full((training.nusers(), training.nitems()), np.arange(training.nitems())).flatten()\n",
    "        self.scores = self.model.predict([uexplode, iexplode], batch_size=training.nusers()*100, \n",
    "                            verbose=1).reshape(training.nusers(), training.nitems())\n",
    "\n",
    "    def create_model(self, ratings, k, lrate, neg, nepochs):\n",
    "        # 'users' is an input layer of type tf.int64.\n",
    "        users = tf.keras.layers.Input(shape=(), dtype=tf.int64, name=\"users\")\n",
    "        user_embeddings = tf.keras.layers.Embedding(\n",
    "                                input_dim=ratings.nusers(),\n",
    "                                output_dim=k,\n",
    "                                name=\"user_embedding\"\n",
    "                            )(users)\n",
    "        # 'items' is an input layer of type tf.int64.\n",
    "        items = tf.keras.layers.Input(shape=(), dtype=tf.int64, name=\"items\")\n",
    "        item_embeddings = tf.keras.layers.Embedding(\n",
    "                                input_dim=ratings.nitems(),\n",
    "                                output_dim=k,\n",
    "                                name=\"item_embedding\"\n",
    "                            )(items)\n",
    "        # TensorFlow has a built-in dot-product layer.\n",
    "        dot = tf.keras.layers.Dot(axes=1, normalize=False)([user_embeddings, item_embeddings])\n",
    "        # Now we need a generic model that wraps up the \"network\", specifying the input and output layers.\n",
    "        model = tf.keras.Model(inputs=[users, items], outputs=dot)\n",
    "\n",
    "        # Compile the model: Adam optimizer is suggested here over SGD.\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "            loss='mse'\n",
    "        )\n",
    "\n",
    "        # Show the model topology\n",
    "        model.summary()\n",
    "        tf.keras.utils.plot_model(model, show_shapes=True, dpi=150)\n",
    "        \n",
    "        hist = self.train_model(ratings, model, neg, nepochs)\n",
    "        return model, hist\n",
    "\n",
    "    def train_model(self, ratings, tf_mf, neg, nepochs):\n",
    "        # We inject 'neg' negative samples for every available rating in the training data\n",
    "        nneg = neg * ratings.nratings()\n",
    "        user_ids = np.concatenate(([ratings.uid_to_uidx(u) for u in ratings.data.u], np.random.choice(list(ratings.uidxs.values()), size=nneg)))\n",
    "        item_ids = np.concatenate(([ratings.iid_to_iidx(u) for u in ratings.data.i], np.random.choice(list(ratings.iidxs.values()), size=nneg)))\n",
    "        rs = ratings.matrix()[user_ids, item_ids]\n",
    "        batch_size = ratings.nratings() + nneg # Single batch with all the data at once.\n",
    "        \n",
    "        # Your code here... to actually do the training\n",
    "        hist = tf_mf.fit(\n",
    "            x=[user_ids, item_ids],\n",
    "            y=rs,\n",
    "            epochs=nepochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0,\n",
    "            callbacks=[TqdmCallback(verbose=0)]\n",
    "        ) # Produces a prettier progress bar.\n",
    "        return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3YGEGm7haop",
    "tags": []
   },
   "source": [
    "### Ejercicio 2 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3ti8qGedgNB",
    "tags": []
   },
   "source": [
    "## Ejercicio 3: Implementación modelo Two-Tower\n",
    "\n",
    "Implementar tu propia versión de un modelo Two-Tower a partir de la arquitectura implementada de MF en el ejercicio anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wzZ-6OG0dvwX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TwoTowerRecommender(DLMFRecommender):\n",
    "    def create_model(self, ratings, k, lrate, neg, nepochs):\n",
    "        # Torre de usuarios:\n",
    "        users = tf.keras.layers.Input(shape=(), dtype=tf.int64, name=\"users\")\n",
    "        user_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=ratings.nusers(),\n",
    "            output_dim=k,\n",
    "            name=\"user_embedding\"\n",
    "        )(users)\n",
    "        # Aplanamos el embedding y agregamos una capa densa para transformar la representación\n",
    "        user_vector = tf.keras.layers.Flatten()(user_embedding)\n",
    "        user_dense = tf.keras.layers.Dense(k, activation=\"relu\", name=\"user_dense\")(user_vector)\n",
    "        \n",
    "        # Torre de ítems:\n",
    "        items = tf.keras.layers.Input(shape=(), dtype=tf.int64, name=\"items\")\n",
    "        item_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=ratings.nitems(),\n",
    "            output_dim=k,\n",
    "            name=\"item_embedding\"\n",
    "        )(items)\n",
    "        item_vector = tf.keras.layers.Flatten()(item_embedding)\n",
    "        item_dense = tf.keras.layers.Dense(k, activation=\"relu\", name=\"item_dense\")(item_vector)\n",
    "        \n",
    "        # Combinación de las dos torres mediante producto punto:\n",
    "        dot = tf.keras.layers.Dot(axes=1, normalize=False, name=\"dot_product\")([user_dense, item_dense])\n",
    "        \n",
    "        # Definición y compilación del modelo:\n",
    "        model = tf.keras.Model(inputs=[users, items], outputs=dot)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate), loss='mse')\n",
    "        \n",
    "        # Mostrar la arquitectura y generar el gráfico del modelo:\n",
    "        model.summary()\n",
    "        tf.keras.utils.plot_model(model, show_shapes=True, dpi=150)\n",
    "        \n",
    "        # Entrenamiento del modelo (utilizando el método heredado train_model)\n",
    "        hist = self.train_model(ratings, model, neg, nepochs)\n",
    "        return model, hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVzsIg0Zev7a",
    "tags": []
   },
   "source": [
    "## Ejercicio 4: Recomendación secuencial [ACTUALIZADO 3 de Marzo]\n",
    "\n",
    "Vas a implementar tu propia versión de un modelo basado en Transformers, en concreto, la del algoritmo SASRec, que incluye un embedding posicional y un modelo causal en la capa de atención.\n",
    "\n",
    "Para ello, puedes revisar la siguiente implementación de un modelo basado en GRU, aunque tu versión puede hacer un procesamiento por lotes mucho más sencillo (aquí se han hecho los mismos mini-lotes en paralelo que en la propuesta original)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionDataset:\n",
    "      def __init__(self, df, n):\n",
    "          self.df = df.sort_values(by = ['s', 't']).reset_index(drop = True)\n",
    "          self.offsets    = np.concatenate((np.zeros(1, dtype = np.int32), self.df.groupby('s').size().cumsum().values))\n",
    "          self.n_sessions = len(self.offsets) - 1\n",
    "          self.item_to_id = {item : i for i, item in enumerate(self.df.i.unique())}\n",
    "          self.n_items = len(self.item_to_id)\n",
    "          self.n = n\n",
    "\n",
    "      def item_to_one_hot(self, item):\n",
    "          return tf.one_hot(self.item_to_id[item], depth = self.n)\n",
    "\n",
    "      def extract_session(self, i, one_hot_encoded = True):\n",
    "          session = self.df[self.offsets[i]:self.offsets[i+1]].copy()\n",
    "          if one_hot_encoded:\n",
    "              session.loc[:, 'i'] = session.i.apply(lambda x : self.item_to_one_hot(x))\n",
    "          return session.i.values.tolist()\n",
    "\n",
    "def from_ratings_to_sessions(ratings, session_size):\n",
    "    ratings_sorted = ratings.data.sort_values(by=[\"u\", \"t\"])\n",
    "    data_sessions = []\n",
    "    cur_session = 0\n",
    "    cur_session_length = 0\n",
    "    cur_user = None\n",
    "    def my_fun(row):\n",
    "        nonlocal data_sessions\n",
    "        nonlocal cur_session\n",
    "        nonlocal cur_session_length\n",
    "        nonlocal cur_user\n",
    "\n",
    "        if not cur_user:\n",
    "            cur_user = row.u\n",
    "        if row.u != cur_user:\n",
    "            cur_user = row.u\n",
    "            cur_session += 1\n",
    "            cur_session_length = 0\n",
    "        if row.u == cur_user:\n",
    "            cur_session_length += 1\n",
    "        data_sessions.append(cur_session)\n",
    "        if session_size and cur_session_length >= session_size:\n",
    "            cur_session += 1\n",
    "            cur_session_length = 0\n",
    "\n",
    "    ratings_sorted.apply(my_fun, axis=1)\n",
    "    sessions = pd.DataFrame(\n",
    "        data={\n",
    "            \"u\": ratings_sorted.u,\n",
    "            \"i\": ratings_sorted.i,\n",
    "            \"r\": ratings_sorted.r,\n",
    "            \"t\": ratings_sorted.t,\n",
    "            \"s\": data_sessions,\n",
    "        }\n",
    "    )\n",
    "    return sessions\n",
    "\n",
    "class GRU4RecRecommender(Recommender):\n",
    "    def __init__(self, training, k=50, nepochs=150, steps_per_epoch=100, ngru_layers=1, batch_size=8, session_length=5, compute_final=False):\n",
    "        super().__init__(training)\n",
    "        # Create the model - this will directly trigger training.        \n",
    "        tf.random.set_seed(0) # For comparability and debugging (the randomness here is in parameter initialization).\n",
    "        dataset = SessionDataset(from_ratings_to_sessions(training, session_length), training.nitems())\n",
    "        self.tf_mf, self.hist = self.create_model(dataset, training.nitems(), k, nepochs, steps_per_epoch, ngru_layers, batch_size)\n",
    "        # Since the network is stateful, the batch size cannot be modified (at least in Keras), so we must always predict batch_size elements at once.\n",
    "        n_classes = training.nitems()\n",
    "        # se deberían calcular los estados ocultos para todas las sesiones, pero tarda mucho\n",
    "        # idealmente, se podría paralelizar este cálculo\n",
    "        if compute_final:\n",
    "            final_states = self._calculate_final_states(dataset, self.tf_mf, ngru_layers, k, batch_size, n_classes)\n",
    "        self._reset_hidden(self.tf_mf, 0)\n",
    "        y_pred = np.empty(shape = (dataset.n_sessions, n_classes))\n",
    "        y_pred[:] = None\n",
    "        X = np.empty(shape = (batch_size, 1, n_classes))\n",
    "        next_session_id = 0\n",
    "        for batch_id in range(dataset.n_sessions // batch_size):\n",
    "            # X contains the penultimate item in the session (= last item in the training set)\n",
    "            X[:] = None\n",
    "            for i in range(batch_size):\n",
    "                X[i, :] = dataset.extract_session(next_session_id)[-1]\n",
    "                next_session_id += 1\n",
    "            nlg = 0\n",
    "            for nl, layer in enumerate(self.tf_mf.layers):\n",
    "                if self._is_GRU_layer(layer):\n",
    "                    self.tf_mf.layers[nl].reset_states()\n",
    "                    nlg += 1\n",
    "            # objective: predict last element in the session\n",
    "            y_pred[batch_id * batch_size : (batch_id + 1) * batch_size, :] = self.tf_mf.predict(X, verbose = 0)[:batch_size]\n",
    "\n",
    "        y_pred = tf.constant(y_pred[:dataset.n_sessions], dtype = tf.float32)\n",
    "        # recover predictions as item scores for each user for classical recommendation (this should not be done in general, but perform a sequential evaluation)\n",
    "        self.scores = y_pred.numpy()\n",
    "\n",
    "    def create_model(self, dataset, n_classes, k, nepochs, steps_per_epoch, ngru_layers, batch_size):\n",
    "        model = tf.keras.models.Sequential(name=\"GRU4Rec\")\n",
    "        for i in range(ngru_layers):\n",
    "            model.add(tf.keras.layers.GRU(name = 'GRU_{}'.format(i+1),\n",
    "                                          units      = k, \n",
    "                                          activation = 'relu', \n",
    "                                          stateful   = True,\n",
    "                                          return_sequences = (i < ngru_layers - 1)))\n",
    "        model.add(tf.keras.layers.Dense(units = n_classes, activation = 'linear'))   # class logits\n",
    "\n",
    "        # track top 3 accuracy (= how often the true item is among the top 3 recommended)\n",
    "        top3accuracy = lambda y_true, y_pred: tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k = 3)\n",
    "        top3accuracy.__name__ = 'top3accuracy'\n",
    "        model.compile(loss = GRU4RecRecommender._TOP1, optimizer = 'adam', metrics = ['accuracy', top3accuracy])\n",
    "\n",
    "        model.build(input_shape = (batch_size, 1, n_classes))\n",
    "        print(model.summary())\n",
    "        \n",
    "        hist = self.train_model(dataset, model, n_classes, batch_size, nepochs, steps_per_epoch)\n",
    "        return model, hist\n",
    "    \n",
    "    def train_batch_generator(self, model, dataset, batch_size, n_classes):\n",
    "        ixs = np.arange(dataset.n_sessions)\n",
    "\n",
    "        stacks = [[]] * batch_size   # stacks containing batch_size REVERSED (pieces of) sessions at once. Will be emptied progressively\n",
    "        next_session_id = 0\n",
    "\n",
    "        X, y = np.empty(shape = (batch_size, 1, n_classes)), np.empty(shape = (batch_size, n_classes)) \n",
    "        while True:\n",
    "            X[:], y[:] = None, None\n",
    "            for i in range(batch_size): # fill in X, y (current batch)\n",
    "                # 1. If stack i is empty (only happens at first round) or has only one element: fill it with a new session\n",
    "                if len(stacks[i]) <= 1:\n",
    "                    while not len(stacks[i]) >= 2:   # ignore sessions with only one element (cannot contribute to the training)\n",
    "                        stacks[i] = dataset.extract_session(ixs[next_session_id])[::-1]  # the data does not have to be all in memory at the same time: we could e.g. load a session at once\n",
    "                        next_session_id += 1\n",
    "                        if next_session_id >= dataset.n_sessions: # no more sessions available: shuffle sessions and restart\n",
    "                            np.random.shuffle(ixs)\n",
    "                            next_session_id = 0\n",
    "                    self._reset_hidden(model, i)   # if session changes, the corresponding hidden state must be reset\n",
    "                # 2. Stack i is now valid: set input + target variables\n",
    "                X[i, 0] = stacks[i].pop()\n",
    "                y[i]    = stacks[i][-1]\n",
    "\n",
    "            yield tf.constant(X, dtype = tf.float32), tf.constant(y, dtype = tf.float32)\n",
    "\n",
    "    def _reset_hidden(self, model, i):\n",
    "        for nl, layer in enumerate(model.layers):   # session has changed: reset corresponding hidden state\n",
    "            if self._is_GRU_layer(layer) and layer.states[0] is not None:\n",
    "                hidden_updated = layer.states[0].numpy()\n",
    "                hidden_updated[i, :] = 0.\n",
    "                model.layers[nl].reset_states()\n",
    "\n",
    "    def _is_GRU_layer(self, layer):\n",
    "        return layer.name.startswith('GRU_')\n",
    "\n",
    "    def train_model(self, dataset, model, n_classes, batch_size, nepochs, steps_per_epoch):\n",
    "        hist = model.fit(self.train_batch_generator(model, dataset, batch_size, n_classes), \n",
    "                            steps_per_epoch = steps_per_epoch, \n",
    "                            epochs          = nepochs,\n",
    "                            callbacks       = [TqdmCallback(verbose=0)], \n",
    "                            shuffle         = False)\n",
    "        return hist\n",
    "    \n",
    "    def _TOP1(y_true, y_pred):\n",
    "        _y_pred = tf.expand_dims(y_pred, axis = -1)\n",
    "        mat = tf.matmul(tf.expand_dims(tf.ones_like(y_true), -1), tf.expand_dims(y_true, axis = 1))\n",
    "        score_diffs = tf.matmul(mat, _y_pred)\n",
    "        score_diffs = tf.squeeze(score_diffs - _y_pred, -1)\n",
    "        loss_by_sample = tf.reduce_sum(tf.nn.sigmoid(tf.square(y_pred)), axis = -1) + \\\n",
    "                          tf.reduce_sum(tf.sigmoid(-score_diffs), axis = -1) + \\\n",
    "                        -tf.squeeze(tf.squeeze(tf.nn.sigmoid(tf.square(tf.matmul(tf.expand_dims(y_true, 1), _y_pred))), -1), -1)\n",
    "        return tf.reduce_sum(loss_by_sample)\n",
    "\n",
    "    def _calculate_final_states(self, dataset, model, n_layers, n_hidden, batch_size, n_classes):\n",
    "        final_states = np.empty(shape = (dataset.n_sessions, n_layers, n_hidden)) # final states will be stored here\n",
    "        final_states[:] = None\n",
    "        done = [False] * dataset.n_sessions   # keep track of the sessions for which the last state has already been calculated\n",
    "\n",
    "        stacks = [dataset.extract_session(i)[::-1] for i in range(batch_size)]\n",
    "        next_session_id = batch_size\n",
    "        batch_idx_to_session = np.arange(batch_size)   # keep track of which session is in each batch element\n",
    "        X = np.empty(shape = (batch_size, 1, n_classes))\n",
    "\n",
    "        self._reset_hidden(model, 0)\n",
    "        n_done = 0\n",
    "        while n_done < dataset.n_sessions:\n",
    "            for i in range(batch_size):\n",
    "                while len(stacks[i]) == 1:  # stack i is at the end\n",
    "                    if not done[batch_idx_to_session[i]]:\n",
    "                        # save final hidden state\n",
    "                        final_states[batch_idx_to_session[i], :] = np.array([layer.states[0][i, :] for layer in model.layers if self._is_GRU_layer(layer)])\n",
    "                        done[batch_idx_to_session[i]] = True\n",
    "                        n_done += 1\n",
    "                        if n_done % 1000 == 0:\n",
    "                            print(\"Progress: {} / {}\".format(n_done, dataset.n_sessions))\n",
    "                    if next_session_id >= dataset.n_sessions: # restart from the beginning (just to reach required batch size)\n",
    "                        next_session_id = 0\n",
    "                    stacks[i] = dataset.extract_session(next_session_id)[::-1]\n",
    "                    batch_idx_to_session[i] = next_session_id\n",
    "                    next_session_id += 1\n",
    "                    self._reset_hidden(model, i)   # session has changed --> reset corresponding hidden state\n",
    "                X[i, 0] = stacks[i].pop()\n",
    "\n",
    "            _ = model.predict(X, verbose = 0)   # hidden states get updated when \"predict\" is called\n",
    "        \n",
    "        return final_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def from_ratings_to_sequences(ratings):\n",
    "    ratings_sorted = ratings.data.sort_values(by=[\"u\", \"t\"])\n",
    "    data_sequences = {}\n",
    "    cur_sequence = 0\n",
    "    cur_user = None\n",
    "    def my_fun(row):\n",
    "        nonlocal data_sequences\n",
    "        nonlocal cur_sequence\n",
    "        nonlocal cur_user\n",
    "\n",
    "        if not cur_user:\n",
    "            cur_user = row.u\n",
    "            data_sequences[cur_sequence] = []\n",
    "        if row.u != cur_user:\n",
    "            cur_user = row.u\n",
    "            cur_sequence += 1\n",
    "            data_sequences[cur_sequence] = []\n",
    "        # append item, but also transform it into index instead of using its id\n",
    "        data_sequences[cur_sequence].append(ratings.iid_to_iidx(row.i))\n",
    "\n",
    "    ratings_sorted.apply(my_fun, axis=1)\n",
    "    return data_sequences\n",
    "\n",
    "class PositionalEmbedding(tf.keras.Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.position_embeddings = tf.keras.layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return inputs + embedded_positions\n",
    "\n",
    "\n",
    "class TransformerRecommender(Recommender):\n",
    "    def __init__(self, training, batch_size=32, dim=128, num_heads=4, nlayers=2, max_len=50, dropout=0.1, nepochs=5, steps_per_epoch=100):\n",
    "        super().__init__(training)\n",
    "        self.max_len = max_len\n",
    "        # Create the model - this will directly trigger training.\n",
    "        tf.random.set_seed(0) # For comparability and debugging (the randomness here is in parameter initialization).\n",
    "        dataset = from_ratings_to_sequences(training)\n",
    "        self.model, self.hist = self.create_model(dataset, training.nitems(), batch_size, dim, num_heads, nlayers, max_len, dropout, nepochs, steps_per_epoch)\n",
    "\n",
    "        padded_sequences = []\n",
    "        for sequence in dataset.values():\n",
    "            # Your code here...\n",
    "            if len(sequence) < self.max_len + 1:\n",
    "                padded = [0] * (self.max_len + 1 - len(sequence)) + sequence\n",
    "            else:\n",
    "                padded = sequence[-(self.max_len + 1):]\n",
    "            # Se utiliza la parte de entrada (todos los tokens excepto el último)\n",
    "            padded_sequences.append(padded[:-1])\n",
    "\n",
    "        input_tensor = tf.constant(padded_sequences, dtype=tf.float32)\n",
    "        logits =  self.model(input_tensor) # Your code here...\n",
    "        scores =  tf.nn.softmax(logits, axis=-1) # Your code here...\n",
    "        # EliminaMOS la primera columna correspondiente al token de padding.\n",
    "        scores = scores[:, 1:]\n",
    "        self.scores = scores.numpy()\n",
    "\n",
    "    def create_model(self, ratings, nitems, batch_size, dim=128, num_heads=4, nlayers=2, max_len=50, dropout=0.1, nepochs=10, steps_per_epoch=100):\n",
    "        inputs = tf.keras.Input(shape=(max_len,))\n",
    "        x = tf.keras.layers.Embedding(nitems + 1, dim, mask_zero=True)(inputs)\n",
    "        x = PositionalEmbedding(max_len, dim)(x) # Your code here...\n",
    "\n",
    "        for _ in range(nlayers):\n",
    "            x_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "            # Usamos max_len ya que es una constante conocida\n",
    "            causal_mask = tf.linalg.band_part(tf.ones((max_len, max_len)), -1, 0)\n",
    "            # Llamar a la capa MultiHeadAttention pasando la máscara\n",
    "            attn_output = tf.keras.layers.MultiHeadAttention(\n",
    "                num_heads=num_heads, key_dim=dim, dropout=dropout\n",
    "            )(x_norm, x_norm, attention_mask=causal_mask) # Your code here...\n",
    "            x = tf.keras.layers.Add()([x, attn_output])\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "            x_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "            ffn_output = tf.keras.layers.Dense(dim * 4, activation='relu')(x_norm) # Your code here...\n",
    "            ffn_output = tf.keras.layers.Dense(dim)(ffn_output) # Your code here...\n",
    "            x = tf.keras.layers.Add()([x, ffn_output])\n",
    "            x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        outputs = tf.keras.layers.Dense(nitems + 1, activation='linear')(x[:, -1, :]) # Your code here...\n",
    "\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"Transformer\")\n",
    "        # Compile the model: Adam optimizer and SparseCategoricalCrossentropy as loss\n",
    "        # Your code here...\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        print(model.summary())\n",
    "        tf.keras.utils.plot_model(model, show_shapes=True, dpi=150)\n",
    "\n",
    "        hist = self.train_model(ratings, model, batch_size, nepochs, steps_per_epoch)\n",
    "        return model, hist\n",
    "\n",
    "    def train_batch_generator(self, dataset, batch_size):\n",
    "        # Convertir el diccionario de secuencias en una lista\n",
    "        sequences = list(dataset.values())\n",
    "        n_sequences = len(sequences)\n",
    "        pointer = 0\n",
    "        # Función auxiliar para hacer padding a cada secuencia (se espera que el target sea el último token)\n",
    "        def pad_sequence(seq, target_length):\n",
    "            if len(seq) < target_length:\n",
    "                return [0] * (target_length - len(seq)) + seq\n",
    "            else:\n",
    "                return seq[-target_length:]\n",
    "        \n",
    "        while True:\n",
    "            X_batch = []\n",
    "            Y_batch = []\n",
    "            for i in range(batch_size):\n",
    "                seq = sequences[pointer]\n",
    "                pointer += 1\n",
    "                if pointer >= n_sequences:\n",
    "                    pointer = 0\n",
    "                    np.random.shuffle(sequences)\n",
    "                # Se requiere que cada ejemplo tenga longitud max_len+1 para separar input y target.\n",
    "                padded = pad_sequence(seq, self.max_len + 1)\n",
    "                # X: los primeros max_len tokens; Y: el token siguiente (último token)\n",
    "                X_batch.append(padded[:-1])\n",
    "                Y_batch.append(padded[-1])\n",
    "            yield tf.constant(X_batch, dtype=tf.int32), tf.constant(Y_batch, dtype=tf.int32)\n",
    "\n",
    "    def train_model(self, dataset, model, batch_size, nepochs, steps_per_epoch):\n",
    "        hist = model.fit(self.train_batch_generator(dataset, batch_size), \n",
    "                            steps_per_epoch = steps_per_epoch, \n",
    "                            epochs          = nepochs,\n",
    "                            callbacks       = [TqdmCallback(verbose=0)], \n",
    "                            shuffle         = False)\n",
    "        return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJDzjUp-hwNZ",
    "tags": []
   },
   "source": [
    "### Ejercicio 4 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpXHr18Cdl2Q",
    "tags": []
   },
   "source": [
    "## Ejercicio 5: Ampliaciones\n",
    "\n",
    "Explorar variaciones sobre una o varias de las implementaciones anteriores, tales como:\n",
    "\n",
    "* En general:\n",
    "    * Además de las métricas de evaluación usadas en la P1 (precision, recall) incluir otras métricas, bien de acierto (NDCG) u otras (cobertura, diversidad, etc.)\n",
    "\n",
    "* Sobre el ejercicio 1 (algoritmo EASE):\n",
    "    * Añadir la opción de asignar 0 a los pesos negativos, comprobando que su eficacia disminuye (como indica el artículo original)\n",
    "\n",
    "* Sobre el ejercicio 2 (factorización de matrices por aprendizaje profundo) y 3 (modelo Two-Tower):\n",
    "    * Diferentes funciones de scoring de pérdida: sigmoide / BCE loss, BCE loss with logits.\n",
    "    * Diferentes optimizadores y configuraciones de los mismos (SGD, Adam, etc.).\n",
    "    * Variaciones en los hiperparámetros y configuración del modelo: learning rate, número de factores k, número de épocas, inicialización de parámetros del modelo, etc.\n",
    "    * Añadir opciones tales como regularización, dropout, etc.\n",
    "    * Añadir capas ocultas en la implementación sobre framework de deep learning.\n",
    "    * Explorar una formulación *pairwise learning to rank* sobre MF (p.e., BPR).\n",
    "\n",
    "* Sobre el ejercicio 4 (recomendación secuencial):\n",
    "    * Estudiar el impacto del tamaño de los lotes (batch_size)\n",
    "    * Prueba otras formas de partir el conjunto de datos y observa si la eficacia de los algoritmos secuenciales cambia\n",
    "\n",
    "Idealmente estas variaciones buscan mejorar la precisión de la recomendación, pero se valorarán intentos interesantes aunque resulten fallidos en ese aspecto.\n",
    "\n",
    "Para probar las implementaciones deberá completarse la función `student_test()` para ilustrar la ejecución de las variantes adicionales, y se incluirán las filas que correspondan en la tabla del apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric():\n",
    "    def __init__(self, cutoff):\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "    def __repr__(self):\n",
    "        return type(self).__name__ + ('@' + str(self.cutoff) if self.cutoff != np.inf else '')\n",
    "\n",
    "class Precision(Metric):\n",
    "    def __init__(self, test, cutoff=np.inf, threshold=1):\n",
    "        super().__init__(cutoff)\n",
    "        self.test = test\n",
    "        # Umbral para considerar un ítem como relevante\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def compute(self, recommendation):\n",
    "        k_recommendations = recommendation.ranked_iidx()[:, :self.cutoff]\n",
    "        \n",
    "        x = np.take_along_axis(self.test.matrix(), k_recommendations, axis=1)\n",
    "        relevant_m = x >= self.threshold\n",
    "\n",
    "        return (np.sum(relevant_m, axis=1) / self.cutoff).mean()\n",
    "\n",
    "class Recall(Metric):\n",
    "    def __init__(self, test, cutoff=np.inf, threshold=1):\n",
    "        super().__init__(cutoff)\n",
    "        self.test = test\n",
    "        self.threshold = threshold\n",
    "        self.individual_relevant = np.sum(test.matrix() >= threshold, axis=1)\n",
    "        self.individual_relevant[self.individual_relevant == 0] = 1\n",
    "\n",
    "    def compute(self, recommendation):\n",
    "        k_recommendations = recommendation.ranked_iidx()[:, :self.cutoff]\n",
    "        \n",
    "        x = np.take_along_axis(self.test.matrix(), k_recommendations, axis=1)\n",
    "        relevant_m = x >= self.threshold\n",
    "\n",
    "        return (np.divide(np.sum(relevant_m, axis=1), self.individual_relevant)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MOfT2yZGpMNi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Código aquí: clases, funciones...\n",
    "\n",
    "def student_test():\n",
    "    # Código de prueba aquí...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucORmwfCh4Um",
    "tags": []
   },
   "source": [
    "### Ejercicio 5 &ndash; Explicación/documentación\n",
    "\n",
    "(por hacer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda de prueba\n",
    "\n",
    "Descarga los ficheros de datos y coloca sus contenidos en una carpeta **data** en el mismo directorio que este *notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Testing MovieLens '1 million' dataset\n",
      "\u001b[34mReading the data at 13:31:12...\u001b[0m\n",
      "Ratings matrix takes 85.4 MB in RAM\n",
      "\u001b[34m--> elapsed time: 0:00:03 <--\u001b[0m\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ users (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ items (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">302,000</span> │ users[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">185,300</span> │ items[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ users (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ items (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │    \u001b[38;5;34m302,000\u001b[0m │ users[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │    \u001b[38;5;34m185,300\u001b[0m │ items[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ item_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">487,300</span> (1.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m487,300\u001b[0m (1.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">487,300</span> (1.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m487,300\u001b[0m (1.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:17<00:00,  3.42s/epoch, loss=0.228]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step\n",
      "Testing DLMFRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <320:0.0197 939:0.019 2753:0.0189 1333:0.0187 1232:0.0187 2211:0.0184 3057:0.0182 3804:0.0172 3622:0.0171 318:0.0166>\n",
      "    User 2 -> <3147:0.0202 886:0.0185 466:0.0184 2473:0.0181 248:0.0177 1732:0.0176 2464:0.0174 784:0.0171 750:0.0169 872:0.0166>\n",
      "    User 3 -> <1617:0.0203 208:0.0202 1721:0.0186 3468:0.0182 3070:0.0174 3531:0.017 2542:0.017 3551:0.0169 1260:0.0167 2342:0.0167>\n",
      "    User 4 -> <1102:0.0202 442:0.0197 1019:0.0194 2219:0.0193 1865:0.0192 2558:0.019 742:0.0187 191:0.0186 1165:0.0183 275:0.018>\n",
      "Precision@10 = 0.023509933774834436\n",
      "Recall@10 = 0.00627535324642281\n",
      "\u001b[34m--> elapsed time: 0:00:24 <--\u001b[0m\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ users (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ items (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">302,000</span> │ users[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │    <span style=\"color: #00af00; text-decoration-color: #00af00\">185,300</span> │ items[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ item_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_product (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ user_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ item_dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ users (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ items (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │    \u001b[38;5;34m302,000\u001b[0m │ users[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │    \u001b[38;5;34m185,300\u001b[0m │ items[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ user_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ item_embedding[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ user_dense (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │      \u001b[38;5;34m2,550\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ item_dense (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │      \u001b[38;5;34m2,550\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_product (\u001b[38;5;33mDot\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ user_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ item_dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">492,400</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m492,400\u001b[0m (1.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">492,400</span> (1.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m492,400\u001b[0m (1.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.86s/epoch, loss=0.185]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 173ms/step\n",
      "Testing TwoTowerRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <858:0.4105 50:0.406 2997:0.4058 1923:0.3934 1240:0.3932 589:0.3912 3751:0.391 1210:0.3866 296:0.3824 3114:0.3776>\n",
      "    User 2 -> <2997:0.653 1617:0.6078 318:0.606 1221:0.5995 608:0.5985 2762:0.5975 924:0.5968 858:0.5853 3114:0.5843 2396:0.5804>\n",
      "    User 3 -> <318:0.4342 2762:0.4266 2028:0.4057 858:0.3966 457:0.3746 3578:0.3711 2396:0.366 296:0.3614 608:0.3579 3052:0.3565>\n",
      "    User 4 -> <2858:0.3163 1617:0.2983 2797:0.2856 608:0.278 541:0.2734 3175:0.2713 1393:0.2703 593:0.2697 1094:0.2672 527:0.266>\n",
      "Precision@10 = 0.12746688741721857\n",
      "Recall@10 = 0.04551890153399358\n",
      "\u001b[34m--> elapsed time: 0:00:32 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing Ease (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <1148:0.4818 1688:0.4764 2565:0.466 2708:0.4592 588:0.451 2983:0.4496 1032:0.4389 1480:0.4337 2087:0.4201 1666:0.4121>\n",
      "    User 2 -> <733:0.6353 1580:0.5979 3118:0.5714 1608:0.5678 957:0.5637 3844:0.5595 349:0.5547 474:0.5513 1099:0.5317 1460:0.5248>\n",
      "    User 3 -> <2918:0.579 2893:0.4919 2635:0.4903 3628:0.4897 1291:0.4816 2791:0.432 2370:0.4314 255:0.4153 2196:0.4103 2729:0.4015>\n",
      "    User 4 -> <1291:0.4874 2534:0.4796 2948:0.4201 1200:0.4167 2571:0.3694 589:0.3528 1791:0.3386 1727:0.3336 3703:0.3321 1655:0.32>\n",
      "Precision@10 = 0.2023509933774834\n",
      "Recall@10 = 0.08744171852376187\n",
      "\u001b[34m--> elapsed time: 0:00:02 <--\u001b[0m\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"GRU4Rec\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"GRU4Rec\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ GRU_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">563,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3706</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">189,006</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ GRU_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │       \u001b[38;5;34m563,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3706\u001b[0m)             │       \u001b[38;5;34m189,006\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">752,706</span> (2.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m752,706\u001b[0m (2.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">752,706</span> (2.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m752,706\u001b[0m (2.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.0039 - loss: 118024.4062 - top3accuracy: 0.0131"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:20<01:21, 20.32s/epoch, accuracy=0.00375, loss=1.18e+5, top3accuracy=0.0125]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 192ms/step - accuracy: 0.0039 - loss: 118019.3750 - top3accuracy: 0.0131\n",
      "Epoch 2/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 9.3140e-04 - loss: 116623.4141 - top3accuracy: 0.0109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:39<00:59, 19.80s/epoch, accuracy=0.00187, loss=1.16e+5, top3accuracy=0.0109]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 194ms/step - accuracy: 9.4074e-04 - loss: 116621.0391 - top3accuracy: 0.0109\n",
      "Epoch 3/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.0021 - loss: 115757.1562 - top3accuracy: 0.0134"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:58<00:39, 19.55s/epoch, accuracy=0.00313, loss=1.16e+5, top3accuracy=0.0125]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 192ms/step - accuracy: 0.0021 - loss: 115756.1328 - top3accuracy: 0.0134\n",
      "Epoch 4/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.0029 - loss: 115250.0938 - top3accuracy: 0.0128"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [01:18<00:19, 19.46s/epoch, accuracy=0.00438, loss=1.15e+5, top3accuracy=0.0128]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - accuracy: 0.0029 - loss: 115250.1016 - top3accuracy: 0.0128\n",
      "Epoch 5/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.0045 - loss: 114563.4219 - top3accuracy: 0.0157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:37<00:00, 19.38s/epoch, accuracy=0.005, loss=1.14e+5, top3accuracy=0.0156]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 192ms/step - accuracy: 0.0045 - loss: 114559.0938 - top3accuracy: 0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:37<00:00, 19.51s/epoch, accuracy=0.005, loss=1.14e+5, top3accuracy=0.0156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GRU4RecRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <64:0.2867 140:0.2739 99:0.2627 17:0.2407 80:0.2407 525:0.2274 8:0.2237 133:0.22 135:0.2199 533:0.2166>\n",
      "    User 2 -> <64:0.2623 140:0.2518 150:0.2495 99:0.2435 17:0.2224 80:0.2207 525:0.2097 8:0.2078 135:0.2048 133:0.2041>\n",
      "    User 3 -> <64:0.32 140:0.3028 150:0.2964 99:0.2883 80:0.2707 17:0.2665 525:0.2487 8:0.2474 133:0.2418 135:0.2366>\n",
      "    User 4 -> <64:0.2806 140:0.2686 150:0.2662 99:0.2581 80:0.2374 17:0.237 525:0.2234 8:0.2221 135:0.2176 133:0.2146>\n",
      "Precision@10 = 0.00026490066225165563\n",
      "Recall@10 = 0.0026490066225165563\n",
      "CategoricalAccuracy@1 = 0.0\n",
      "CategoricalAccuracy@3 = 0.002152318\n",
      "CategoricalAccuracy@10 = 1.0\n",
      "\u001b[34m--> elapsed time: 0:03:31 <--\u001b[0m\n",
      "-------------------------\n",
      "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\Master\\SR\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">474,496</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,808</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ positional_embed… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3707</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">478,203</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m474,496\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m6,400\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m263,808\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ positional_embed… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m66,048\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,664\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3707\u001b[0m)      │    \u001b[38;5;34m478,203\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,355,131</span> (5.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,355,131\u001b[0m (5.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,355,131</span> (5.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,355,131\u001b[0m (5.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m 99/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0053 - loss: 7.9876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:04<00:17,  4.42s/epoch, accuracy=0.00625, loss=7.81]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.0053 - loss: 7.9840\n",
      "Epoch 2/5\n",
      "\u001b[1m 99/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0077 - loss: 7.6233"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:06<00:09,  3.10s/epoch, accuracy=0.00563, loss=7.58]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.0077 - loss: 7.6224\n",
      "Epoch 3/5\n",
      "\u001b[1m 98/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0117 - loss: 7.0276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:08<00:05,  2.66s/epoch, accuracy=0.00969, loss=7.04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.0116 - loss: 7.0279\n",
      "Epoch 4/5\n",
      "\u001b[1m 98/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0133 - loss: 7.0455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:10<00:02,  2.47s/epoch, accuracy=0.0134, loss=6.97] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.0133 - loss: 7.0431\n",
      "Epoch 5/5\n",
      "\u001b[1m 99/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0169 - loss: 6.6385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  2.37s/epoch, accuracy=0.0162, loss=6.67]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.0169 - loss: 6.6391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:13<00:00,  2.62s/epoch, accuracy=0.0162, loss=6.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing TransformerRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <2011:0.0057 2627:0.0052 1616:0.0049 2761:0.0044 3526:0.0042 2616:0.0037 3551:0.0037 2857:0.0035 3867:0.0033 2354:0.0033>\n",
      "    User 2 -> <3808:0.0221 3272:0.01 2395:0.0094 3767:0.0075 2391:0.0063 3670:0.006 2715:0.0056 1916:0.0053 3395:0.005 2718:0.005>\n",
      "    User 3 -> <2761:0.0438 3526:0.0242 3867:0.016 3792:0.0158 2627:0.0155 3702:0.0145 3752:0.0137 3701:0.0128 1616:0.0127 2790:0.0125>\n",
      "    User 4 -> <3255:0.0506 2570:0.0297 1616:0.0295 3526:0.0255 2616:0.0181 2761:0.018 3159:0.0141 2627:0.0129 3174:0.0129 3752:0.012>\n",
      "Precision@10 = 0.0009602649006622518\n",
      "Recall@10 = 0.009602649006622516\n",
      "CategoricalAccuracy@1 = 0.12798013\n",
      "CategoricalAccuracy@3 = 0.33129138\n",
      "CategoricalAccuracy@10 = 1.0\n",
      "\u001b[34m--> elapsed time: 0:00:22 <--\u001b[0m\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">474,496</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,400</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,808</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ positional_embed… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,808</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3707</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">478,203</span> │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m474,496\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m6,400\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ positional_embed… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m263,808\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ positional_embed… │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m66,048\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,664\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m263,808\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m66,048\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m65,664\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3707\u001b[0m)      │    \u001b[38;5;34m478,203\u001b[0m │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,751,163</span> (6.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,751,163\u001b[0m (6.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,751,163</span> (6.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,751,163\u001b[0m (6.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0045 - loss: 8.0110"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:07<00:30,  7.72s/epoch, accuracy=0.005, loss=7.84]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.0045 - loss: 8.0093\n",
      "Epoch 2/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0073 - loss: 7.6888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:11<00:16,  5.52s/epoch, accuracy=0.005, loss=7.64]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.0072 - loss: 7.6883\n",
      "Epoch 3/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0069 - loss: 7.0744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:15<00:09,  4.85s/epoch, accuracy=0.0075, loss=7.14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.0069 - loss: 7.0750\n",
      "Epoch 4/5\n",
      "\u001b[1m 99/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0098 - loss: 7.1848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:19<00:04,  4.57s/epoch, accuracy=0.00906, loss=7.09]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.0098 - loss: 7.1829\n",
      "Epoch 5/5\n",
      "\u001b[1m 99/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0156 - loss: 6.7822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.36s/epoch, accuracy=0.0122, loss=6.83] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.0155 - loss: 6.7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:23<00:00,  4.78s/epoch, accuracy=0.0122, loss=6.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing TransformerRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <3498:0.009 3362:0.0089 3896:0.0078 3670:0.0067 2986:0.0067 1392:0.0057 3749:0.0056 2699:0.0052 3577:0.0052 2761:0.0051>\n",
      "    User 2 -> <2806:0.0146 180:0.0106 3801:0.0101 1830:0.0093 2001:0.0092 1421:0.0078 1881:0.0077 2642:0.0075 3766:0.0075 2392:0.0073>\n",
      "    User 3 -> <3362:0.0099 3420:0.0097 3896:0.0092 3702:0.0063 2699:0.0056 1999:0.0055 2986:0.0048 2627:0.0047 3749:0.0045 2173:0.0044>\n",
      "    User 4 -> <2984:0.0068 180:0.0065 1881:0.0064 2642:0.0059 2627:0.0058 3701:0.0054 3623:0.0054 2950:0.0053 2477:0.0051 3840:0.005>\n",
      "Precision@10 = 0.000794701986754967\n",
      "Recall@10 = 0.007947019867549669\n",
      "CategoricalAccuracy@1 = 0.13592716\n",
      "CategoricalAccuracy@3 = 0.3213576\n",
      "CategoricalAccuracy@10 = 1.0\n",
      "\u001b[34m--> elapsed time: 0:00:34 <--\u001b[0m\n",
      "=========================\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import datetime, time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class CategoricalAccuracy(Metric):\n",
    "    def __init__(self, test, cutoff=np.inf):\n",
    "        super().__init__(cutoff)\n",
    "        dataset = from_ratings_to_sequences(test)\n",
    "        y_true = np.empty(shape = (len(dataset), 1))\n",
    "        for i in range(y_true.shape[0]):\n",
    "            y_true[i, :] = dataset[i][:1]\n",
    "        self.y_true = tf.constant(y_true, dtype = tf.float32)\n",
    "\n",
    "    def compute(self, recommendation):\n",
    "        y_pred = tf.constant(recommendation.ranked_iidx(), dtype = tf.float32)\n",
    "        acc = (tf.reduce_sum(tf.keras.metrics.top_k_categorical_accuracy(self.y_true, y_pred, k = self.cutoff)) / self.y_true.shape[0]).numpy()\n",
    "        return acc\n",
    "\n",
    "\n",
    "# Test data structures and algorithms on a dataset.\n",
    "def test(ratings_file, topn=np.inf, cutoff=np.inf, threshold=1, sep=','):\n",
    "    print(colored(f'Reading the data at ' + time.strftime('%X...'), 'blue'))\n",
    "    start = time.time()\n",
    "    ratings = Ratings(ratings_file, sep)\n",
    "    print(f'Ratings matrix takes {round(10 * ratings.matrix().nbytes / 1024 / 1024) / 10:,} MB in RAM')\n",
    "    timer(start)\n",
    "\n",
    "    # Produce a rating split and test a set of recommenders. \n",
    "    train, test = ratings.random_split(0.8)\n",
    "    train_temp, test_temp = ratings.peruser_sequence_split(ntestitems=1)\n",
    "    metrics = [Precision(test, cutoff=cutoff, threshold=threshold), Recall(test, cutoff=cutoff, threshold=threshold)]\n",
    "    metrics_temp = [Precision(test_temp, cutoff=cutoff, threshold=threshold), Recall(test_temp, cutoff=cutoff, threshold=threshold), CategoricalAccuracy(test_temp, cutoff=1), CategoricalAccuracy(test_temp, cutoff=3), CategoricalAccuracy(test_temp, cutoff=cutoff)]\n",
    "    run_recommenders(train, metrics, topn)\n",
    "    run_temp_recommenders(train_temp, metrics_temp, topn)\n",
    "\n",
    "\n",
    "# Run some recommenders on the some rating data as input - no evaluation.\n",
    "def run_recommenders(train, metrics, topn):\n",
    "    print('-------------------------')\n",
    "    start = time.time()\n",
    "    run_recommender(DLMFRecommender(train, nepochs=5), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    run_recommender(TwoTowerRecommender(train, nepochs=5), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    run_recommender(Ease(train, threshold=1), metrics, topn)\n",
    "    timer(start)\n",
    "\n",
    "def run_temp_recommenders(train, metrics, topn):\n",
    "    print('-------------------------')\n",
    "    start = time.time()\n",
    "    run_recommender(GRU4RecRecommender(train, nepochs=5, session_length=None, batch_size=32), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    run_recommender(TransformerRecommender(train, nlayers=1), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    run_recommender(TransformerRecommender(train, nlayers=2), metrics, topn)\n",
    "    timer(start)\n",
    "\n",
    "# Run a recommender and evaluate a list of metrics on its output.\n",
    "def run_recommender(recommender, metrics, topn):\n",
    "    print(f'Testing {recommender} (top {topn})')\n",
    "    recommendation = recommender.recommend(topn)\n",
    "    print('Four example recommendations:\\n' + recommendation.display(4))\n",
    "    for metric in metrics:\n",
    "        print(metric, '=', metric.compute(recommendation))\n",
    "\n",
    "from termcolor import colored\n",
    "def timer(start):\n",
    "    print(colored(f'--> elapsed time: {datetime.timedelta(seconds=round(time.time() - start))} <--', 'blue'))\n",
    "    return time.time()\n",
    "    \n",
    "np.random.seed(0)\n",
    "print('=========================\\nTesting MovieLens \\'1 million\\' dataset')\n",
    "test('data/ratings-1m.dat', topn=10, cutoff=10, sep='::')\n",
    "print('=========================\\nDone.')\n",
    "\n",
    "# Additional testing?\n",
    "student_test()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Enunciado P2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
