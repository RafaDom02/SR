{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2024 Pablo Castells y Alejandro Bellogín\n",
    "\n",
    "El código que contiene este notebook se ha implementado para la realización de las prácticas de la asignatura \"Búsqueda y minería de información\" de 4º del Grado en Ingeniería Informática, impartido en la Escuela Politécnica Superior de la Universidad Autónoma de Madrid. El fin del mismo, así como su uso, se ciñe a las actividades docentes de dicha asignatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKBXprvhpqQr"
   },
   "source": [
    "### **Búsqueda y Minería de Información 2023-24**\n",
    "### Universidad Autónoma de Madrid, Escuela Politécnica Superior\n",
    "### Grado en Ingeniería Informática, 4º curso\n",
    "\n",
    "# Sistemas de recomendación\n",
    "\n",
    "Fechas:\n",
    "\n",
    "* Comienzo: martes 2 / jueves 4 de abril.\n",
    "* Entrega: lunes 6 de mayo, 23:59.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "Esta práctica tiene por objetivo la implementación y evaluación eficiente de sistemas de recomendación. En este bloque se desarrollarán:\n",
    "\n",
    "* Estructuras para el manejo de datos de interacción entre usuarios e items (diremos \"ratings\" para simplificar).\n",
    "* Algoritmos de recomendación basada en filtrado colaborativo.\n",
    "* Métricas de evaluación de sistemas de recomendación.\n",
    "\n",
    "## Material proporcionado\n",
    "\n",
    "Se proporcionan software y datos para la realización de la práctica:\n",
    "\n",
    "* Un esqueleto de clases y funciones donde el estudiante desarrollará sus implementaciones. \n",
    "  - De modo similar a las prácticas anteriores, se proporciona una celda de prueba al final de este notebook que deberá funcionar con las implementaciones del estudiante.\n",
    "  - Junto a la celda de prueba en este mismo notebook, se muestra como referencia un ejemplo de salida generada con una implementación de los profesores.\n",
    "* Los siguientes conjuntos de datos de ratings por usuarios a items:\n",
    "  - Dos conjuntos de juguete para prueba y depuración: <ins>toy1.csv</ins> (se genera en Matrices.ipynb) y <ins>toy2.csv</ins> (proporcionado en el curso Moodle) con ratings ficticios.\n",
    "  - Un conjunto de datos reales de ratings a películas: *ml-1m.zip* disponible en la Web de [MovieLens](https://grouplens.org/datasets/movielens/1m). De los archivos disponibles, se utilizará sólamente <ins>ratings.dat</ins>, añadiéndole una cabecera `u::i::r::t`.\n",
    "  \n",
    "Los esqueletos de código que se proporcionan aquí son a modo de guía: el estudiante puede modificarlo todo libremente, siempre que la celda de prueba funcione correctamente **sin cambios**.\n",
    "\n",
    "## Calificación\n",
    "\n",
    "El peso de esta práctica en la nota final de prácticas es del **40%**.\n",
    "\n",
    "La calificación se basará en el **número** de ejercicios realizados y la **calidad** de los mismos. La puntuación que se indica en cada apartado es orientativa, en principio se aplicará tal cual se refleja pero podrá matizarse por criterios de buen sentido si se da el caso.\n",
    "\n",
    "Para dar por válida la realización de un ejercicio, el código deberá funcionar (a la primera) integrado con las clases que se facilitan. El profesor comprobará este aspecto ejecutando la celda de prueba y otras adicionales.\n",
    "\n",
    "La corrección de las implementaciones se observará por la **coherencia de los resultados** (por ejemplo, las métricas sobre los algoritmos de recomendación), y se valorará la eficiencia en tiempo de ejecución.\n",
    "\n",
    "## Entrega\n",
    "\n",
    "La entrega consistirá en un fichero tipo *notebook* donde se incluirán todas las **implementaciones** solicitadas en cada ejercicio, así como una explicación de cada uno a modo de **memoria**.\n",
    "\n",
    "## Indicaciones\n",
    "\n",
    "La realización de los ejercicios conducirá en muchos casos a la implementación de funciones y/o clases adicionales a las que se indican en el enunciado. Algunas vendrán dadas por su aparición en los propias celdas de prueba, y otras por conveniencia a criterio del estudiante.\n",
    "\n",
    "Igual que en prácticas anteriores, no deberá editarse la celda de prueba. Esta celda deberá ejecutar sin errores a la primera con el código entregado por el estudiante (naturalmente con salvedad de los ejercicios que no se hayan implementado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ejercicio 1: Estructuras de datos y recomendación simple (2pt)\n",
    "\n",
    "#### 1.1 &nbsp; Estructuras de datos\n",
    "\n",
    "Implementar las clases necesarias para manejar **datos de entrada y prueba** (ratings) para los algoritmos de recomendación. La funcionalidad se implementará en una clase Ratings, que permitirá leer los datos de un fichero de texto, así como un método que genere dos particiones aleatorias de entrenamiento y test, para evaluar y comparar la efectividad de diferentes algoritmos de recomendación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "class Ratings:\n",
    "    def __init__(self, file=None, sep=','):\n",
    "        \"\"\"\n",
    "        Constructor method for this class. Reads a ratings matrix from file and\n",
    "        loads it to memory.\n",
    "\n",
    "        Args:\n",
    "            file (str): path for the csv file where the matrix is stored.\n",
    "            sep (str): separation between elements in the csv file.\n",
    "        \"\"\"\n",
    "        ratings_df = pd.read_csv(file, sep=sep)\n",
    "        self.m = ratings_df.pivot_table(index='u', columns='i', values='r', fill_value=0).to_numpy()\n",
    "        \n",
    "        # Conversion tables\n",
    "        self.t_uidx_to_uid = np.sort(ratings_df.u.unique())\n",
    "        self.t_iidx_to_iid = np.sort(ratings_df.i.unique())\n",
    "        # Conversion dictionaries\n",
    "        self.d_uid_to_uidx = { k:i for i,k in enumerate(self.t_uidx_to_uid)}\n",
    "        self.d_iid_to_iidx = { k:j for j,k in enumerate(self.t_iidx_to_iid)}\n",
    "\n",
    "    \n",
    "    def matrix(self):\n",
    "        \"\"\"\n",
    "        Returns the ratings matrix of this object.\n",
    "        \"\"\"\n",
    "        return self.m\n",
    "    \n",
    "    def nusers(self):\n",
    "        \"\"\"\n",
    "        Returns the number of users in the matrix.\n",
    "        \"\"\"\n",
    "        return self.t_uidx_to_uid.shape[0]\n",
    "    \n",
    "    def nitems(self):\n",
    "        \"\"\"\n",
    "        Returns the number of items in the matrix.\n",
    "        \"\"\"\n",
    "        return self.t_iidx_to_iid.shape[0]\n",
    "    \n",
    "    # uidx can be an int or an array-like of ints.\n",
    "    def uidx_to_uid(self, uidx):\n",
    "        \"\"\"\n",
    "        Returns an explicit representation for an user id.\n",
    "\n",
    "        Args:\n",
    "            uidx (int): user id, an index for the ratings matrix.\n",
    "        \"\"\"\n",
    "        return self.t_uidx_to_uid[uidx]\n",
    "        \n",
    "    # iidx can be an int or an array-like of ints.\n",
    "    def iidx_to_iid(self, iidx):\n",
    "        \"\"\"\n",
    "        Returns an explicit representation for an item id.\n",
    "        \n",
    "        Args:\n",
    "            iidx (int): item id, an index for the ratings matrix.\n",
    "        \"\"\"\n",
    "        return self.t_iidx_to_iid[iidx]\n",
    "    \n",
    "    def uid_to_uidx(self, uid):\n",
    "        \"\"\"\n",
    "        Returns an implicit id for a user representation.\n",
    "\n",
    "        Args:\n",
    "            uid (Any): User representation.\n",
    "        \"\"\"\n",
    "        return self.d_uid_to_uidx[uid]\n",
    "        \n",
    "    def iid_to_iidx(self, iid):\n",
    "        \"\"\"\n",
    "        Returns an implicit id for an item representation.\n",
    "\n",
    "        Args:\n",
    "            iid (Any): Item representation.\n",
    "        \"\"\"\n",
    "        return self.d_iid_to_iidx[iid]\n",
    "        \n",
    "    def iidx_rated_by(self, uidx):\n",
    "        \"\"\"\n",
    "        Returns the indices of items rated by the user with the given id.\n",
    "\n",
    "        Args:\n",
    "            uidx (int): user id, an index for the ratings matrix.\n",
    "        \"\"\"\n",
    "        return np.ndarray.nonzero(self.m[uidx])\n",
    "        \n",
    "    def uidx_who_rated(self, iidx):\n",
    "        \"\"\"\n",
    "        Returns the indices of users that rated this item with the given index.\n",
    "        \n",
    "        Args:\n",
    "            iidx (int): item id, an index for the ratings matrix.\n",
    "        \"\"\"\n",
    "        return np.ndarray.nonzero(self.m[:, iidx])\n",
    "        \n",
    "    def random_split(self, ratio):\n",
    "        \"\"\"\n",
    "        Randomly splits the ratings matrix between two submatrices.\n",
    "\n",
    "        Args:\n",
    "            ratio (float): probability of an item going in the first submatrix.\n",
    "\n",
    "        Returns:\n",
    "            Two submatrices with the split items.\n",
    "        \"\"\"\n",
    "        c1 = copy.deepcopy(self)\n",
    "        c2 = copy.deepcopy(self)\n",
    "\n",
    "        mask = np.random.choice([1, 0], size=self.m.shape, p=[ratio,1-ratio])\n",
    "\n",
    "        c1.m = c1.m * mask\n",
    "        c2.m = c2.m * (1 - mask)\n",
    "        \n",
    "        return c1,c2\n",
    "\n",
    "    #\n",
    "    # The remaining functions are just for debugging purposes\n",
    "    #\n",
    "\n",
    "    def rating(self, uid, iid):\n",
    "        \"\"\"\n",
    "        Returns the user rating for the specified item.\n",
    "\n",
    "        Args:\n",
    "            uid (Any): User representation.\n",
    "            iid (Any): Item representation.\n",
    "        \"\"\"\n",
    "        return self.m[self.d_uid_to_uidx[uid], self.d_idd_to_iidx[iid]]\n",
    "\n",
    "    def items_rated_by(self, uid):\n",
    "        \"\"\"\n",
    "        Returns the indices of items rated by the user.\n",
    "\n",
    "        Args:\n",
    "            uid (Any): User representation.\n",
    "        \"\"\"\n",
    "        return self.iidx_rated_by(self.d_uid_to_uidx[uid])\n",
    "        \n",
    "    def users_who_rated(self, iid):\n",
    "        \"\"\"\n",
    "        Returns the indices of users that rated this item.\n",
    "\n",
    "        Args:\n",
    "            iid (Any): Item representation.\n",
    "        \"\"\"\n",
    "        return self.uidx_who_rated(self.d_iid_to_iidx[iid])\n",
    "    \n",
    "    def user_ratings(self, uid):\n",
    "        \"\"\"\n",
    "        Returns an item:rating dictionary of items rated by the user.\n",
    "\n",
    "        Args:\n",
    "            uid (Any): User representation.\n",
    "        \"\"\"\n",
    "        uidx = self.d_uid_to_uidx[uid]\n",
    "        indices = self.iidx_rated_by(uidx)\n",
    "        return {item:rating for item, rating in zip(self.t_iidx_to_iid[indices], self.m[uidx][indices])}\n",
    "\n",
    "    def item_ratings(self, iid):\n",
    "        \"\"\"\n",
    "        Returns the indices of users that rated this item.\n",
    "        \n",
    "        Args:\n",
    "            iid (Any): Item representation.\n",
    "        \"\"\"\n",
    "        iidx = self.d_iid_to_iidx[iid]\n",
    "        indices = self.uidx_who_rated(self.d_iid_to_iidx[iid])\n",
    "        return {item:rating for item, rating in zip(self.t_uidx_to_uid[indices], self.m[:,iidx][indices])}\n",
    "    \n",
    "    def nratings(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of ratings in the matrix.\n",
    "        \"\"\"\n",
    "        return np.count_nonzero(self.m)\n",
    "        \n",
    "    # To inspect random data splits.\n",
    "    def save(self, file):\n",
    "        \"\"\"\n",
    "        Saves the ratings matrix in the given filename.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(columns=self.iids, index=self.uids, data=self.m).unstack().reset_index(name='r')\n",
    "        df.columns = ['i', 'u', 'r']\n",
    "        df = df[df.r>0][['u', 'i', 'r']].sort_values(by=['u', 'i'])\n",
    "        df.to_csv(file, index=False)\n",
    "\n",
    "# Just for pretty-printing numbers.\n",
    "def fround(x, n=20):\n",
    "    r = round(x)\n",
    "    rn = round(x, n)\n",
    "    return r if rn == r else rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 &nbsp;  Recomendaciones: métodos simples no personalizados\n",
    "\n",
    "La **salida** de un recomendador consistirá en un diccionario con un ránking por usuario. \n",
    "\n",
    "Implementar un primer **recomendador simple** por rating promedio en una clase `AverageRecommender`. El recomendador sólo recomendará items que tengan un mínimo número de ratings, que se indicará como parámetro en el constructor (con ello se mejora el acierto de la recomendación). Se proporciona una clase `MajorityRecommender` a modo de ejemplo en el que el estudiante podrá basarse, así como `RandomRecommender`, que se utiliza en ocasiones como referencia en experimentos.\n",
    "\n",
    "\n",
    "\n",
    "**Importante**: recordar que no deben recomendarse los items que los usuarios ya hayan puntuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suggestion: compute the scores in each recommenders' constructor.\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "# Given a matrix, .\n",
    "def top_positions_per_row(m, k):\n",
    "    \"\"\"\n",
    "    Returns a matrix of positions of top k values per row.\n",
    "\n",
    "    Args:\n",
    "        m (np.ndarray): Ratings matrix.\n",
    "        k (int): top positions to return per row.\n",
    "    \"\"\"\n",
    "\n",
    "    if (type(m) != np.ndarray):\n",
    "        n = m.toarray()\n",
    "        np.argpartition(m.col, k)\n",
    "    else:\n",
    "        return np.argpartition(m, -k)[:, -k:]\n",
    "        \n",
    "def top_positions_per_row2(m, k):\n",
    "    \"\"\"\n",
    "    Returns a matrix of positions of top k values per row.\n",
    "\n",
    "    Args:\n",
    "        m (np.ndarray): Ratings matrix.\n",
    "        k (int): top positions to return per row.\n",
    "    \"\"\"\n",
    "    return np.argpartition(m, -k)[:, -k:]\n",
    "    \n",
    "class Recommendation:\n",
    "    def __init__(self, scores, n, training):\n",
    "        # Remove previosuly rated items\n",
    "        mask = training.matrix() == 0\n",
    "        self.scores = scores * mask\n",
    "\n",
    "        # Get the top n positions per row\n",
    "        top_iidx = np.sort(top_positions_per_row(self.scores, n))\n",
    "        self.ranked_iidx_m = np.take_along_axis(top_iidx, np.argsort(np.take_along_axis(-self.scores, top_iidx, axis=1)), axis=1)\n",
    "\n",
    "        # Get the iids of the elements\n",
    "        ranked_iids = training.iidx_to_iid(self.ranked_iidx_m)\n",
    "        self.rank_scores = np.take_along_axis(self.scores, self.ranked_iidx_m, axis=1)\n",
    "\n",
    "        # Recommendations!\n",
    "        self._recommendation = {uid : [(iid, score) for iid, score in zip(ranked_iids[uidx], self.rank_scores[uidx]) if score > 0] \n",
    "        for uidx, uid in enumerate(training.t_uidx_to_uid)} \n",
    "        \n",
    "    def ranked_iidx(self):\n",
    "        return self.ranked_iidx_m\n",
    "\n",
    "    def score_matrix(self):\n",
    "        return self.scores\n",
    "        \n",
    "    def recommendation(self, uid):\n",
    "        return self._recommendation[uid]\n",
    "        \n",
    "    # This function is for debuggind purposes.\n",
    "    # Format the recommendation as a string for the first n users. Trim scores to 4 decimal digits.\n",
    "    def display(self, n):\n",
    "        r = ''\n",
    "        for uid in islice(self._recommendation, n):\n",
    "            r += f'    User {uid} -> <' \n",
    "            for iid, score in self.recommendation(uid): \n",
    "                r += f'{iid}:{str(fround(score, 4))} '\n",
    "            r = (r[:-1] + '>\\n') if len(self.recommendation(uid)) > 0 else r + 'empty>\\n'\n",
    "        return r[:-1]\n",
    "        \n",
    "class Recommender():\n",
    "    def __init__(self, training):\n",
    "        self.training = training\n",
    "\n",
    "    def __repr__(self):\n",
    "        return type(self).__name__\n",
    "\n",
    "    def recommend(self, n):\n",
    "        return Recommendation(self.scores, n, self.training)\n",
    "\n",
    "class RandomRecommender(Recommender):\n",
    "    def __init__(self, training):\n",
    "        super().__init__(training)\n",
    "        self.scores = np.random.random(training.matrix().shape)\n",
    "\n",
    "class MajorityRecommender(Recommender):\n",
    "    def __init__(self, training, threshold=0):\n",
    "        super().__init__(training)\n",
    "        # training.matrix() >= threshold creates a mask with 'True' on relevant ratings and 'False' anywhere\n",
    "        # else. Thus 'pop' is an array with the counts of relevant ratings of each item (since axis=0 applies\n",
    "        # this sum column-wise).\n",
    "        pop = np.sum(training.matrix() >= threshold, axis=0)\n",
    "        # This product by a vector of ones (of user-row length) creates a matrix where the pop vector gets\n",
    "        # copied on all rows; the recommendation is not personalized and ranking is the same for all users \n",
    "        # -- except of course in the end different training items will be filtered out for different users.\n",
    "        self.scores = np.outer(np.ones(training.nusers()), pop)\n",
    "\n",
    "class AverageRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Class definition for a non-personalized recommender based on \n",
    "    the average scores of relevant items. An item is considered\n",
    "    relevant, for this particular case, when it contains a minimum\n",
    "    number of ratings, regardless of their individual score.\n",
    "    \"\"\"\n",
    "    def __init__(self, training, minr=0):\n",
    "        \"\"\"\n",
    "        Constructor method for this class. Computes intermediate scores for\n",
    "        an average-based reccomendation, without removing elements that were\n",
    "        already rated by users.\n",
    "        \"\"\"\n",
    "        super().__init__(training)\n",
    "\n",
    "        # Create a mask for items that were rated at least minr times\n",
    "        # Then mask the ratings matrix\n",
    "        n_ratings = np.count_nonzero(training.matrix(), axis=0)\n",
    "        mask = n_ratings >= minr\n",
    "        mask_scores = (training.matrix() * mask)\n",
    "\n",
    "        # Count the ratings, avoid division by 0 by setting at least 1 rating per item\n",
    "        n_ratings *= mask\n",
    "        n_ratings[n_ratings == 0] = 1\n",
    "\n",
    "        # Compute the user scores as the average of all ratings\n",
    "        self.scores = np.outer(np.ones(training.nusers()), np.sum(mask_scores, axis=0) / n_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3YGEGm7haop",
    "tags": []
   },
   "source": [
    "### Ejercicio 1 &ndash; Explicación/documentación\n",
    "\n",
    "**Ratings**  \n",
    "El objetivo de esta clase es poder implementar las operaciones relevantes a realizar sobre una *matriz de ratings*. Sobre cada uno de los items pertenecientes a una colección, un usuario *u* puede colocar un rating $r(u, i)$; aunque no necesariamente deben poseer un valor. De esta forma, se tiene:\n",
    "\n",
    "- uidx, uid: Identificadores de usuario, tanto (1) numéricos como (2) lógicos (no necesariamente numérico). \n",
    "- iidx, iid: Identificadores de item, tanto (1) numéricos como (2) lógicos (no necesariamente numérico).\n",
    "\n",
    "Los identificadores numéricos representan, en conjunto, el valor $r(u,i)$ dentro de la matriz de ratings, de forma `ratings[uidx][iidx]`. Los identificadores lógicos, en cambio, son las representaciones reales de usuarios e items; que deben ser convertidas a un formato utilizable por la matriz de ratings. Por este motivo, se hace uso de arrays y diccionarios que garantizan esta conversión de forma bidireccional:\n",
    "\n",
    "- t_nidx_to_nid: Array que transforma el tipo de id N de un entero a una representación lógica.\n",
    "- t_nid_to_nidx: Diccionario que garantiza la conversión contraria.\n",
    "\n",
    "Finalmente, y sin tener en cuenta los métodos de debug, otro punto de interés sobre esta clase recae en los *random splits*, que permitirán generar particiones aleatorias sobre la matriz para poder realizar entrenamiento y test de recomendaciones.\n",
    "\n",
    "**Recomendaciones**  \n",
    "Es necesario crear *recomendadores* que permitan, dada la información ya contenida en la matriz, predecir que items serían de interés para los usuarios. Para realzar esto, se habla de *recomendaciones* $\\hat{r}(u, i)$, las cuales calculan estimaciones de rating para usuarios, en base a ciertos parámetros. Para poder saber la efectividad de un recomendador es necesario comparar datos generados con datos reales: por esta razón se utilizan particiones de *entrenamiento* y *test*.\n",
    "\n",
    "Por ejemplo, un recomendador que implementamos es el *AverageRecommender*, el cual es un recomendador no personalizado: en este caso, las similitudes no se tienen en cuenta. Si un item tiene un promedio de ratings muy alto (siempre con un mínimo de recomendaciones), este será recomendado al usuario. De esta forma, todos los vectores de scores obtenidos para cada usuario serán exactamente iguales, y por tanto las recomendaciones también serán las mismas. En cuanto a la clase *Recommendation*, esta simplemente se encarga de acumular los scores calculados por los *recomendadores* y devolver los cutoff resultados más altos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3ti8qGedgNB",
    "tags": []
   },
   "source": [
    "## Ejercicio 2: Filtrado colaborativo kNN (3pt)\n",
    "\n",
    "Implementar un algoritmo de filtrado colaborativo mediante vecinos próximos orientado a usuarios por *similitud coseno* (sin normalizar por la suma de similitudes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wzZ-6OG0dvwX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CosineUserSimilarity:\n",
    "    def __init__(self, training):\n",
    "        # Compute the dot similarity (u * v) of all users\n",
    "        # The diagonal is filled with u^2 values for every user\n",
    "        dot_matrix = training.matrix()@(training.matrix().T)\n",
    "\n",
    "        # Get a vector of user mods, set to 1 when no ratings are given\n",
    "        mods = np.sqrt(np.diag(dot_matrix))\n",
    "        mods[mods==0] = 1\n",
    "\n",
    "        # Create a similarity cosine matrix between users, and set our\n",
    "        # own similarity to 0\n",
    "        self.sim = ((dot_matrix / mods).T / mods).T\n",
    "        np.fill_diagonal(self.sim, 0)\n",
    "\n",
    "    def sim_matrix(self):\n",
    "        return self.sim\n",
    "        \n",
    "\n",
    "class UserKNNRecommender(Recommender):\n",
    "    def __init__(self, training, sim, k):\n",
    "        super().__init__(training)\n",
    "\n",
    "        # Get the k closest neighbours\n",
    "        knn = top_positions_per_row(sim.sim_matrix(), k)\n",
    "\n",
    "        # Create a mask where k neighbours = 1, else 0\n",
    "        mask = np.zeros_like(sim.sim_matrix())\n",
    "        mask[np.arange(mask.shape[0]), knn.T] = 1\n",
    "\n",
    "        # Mask sim matrix\n",
    "        knn_sim = sim.sim_matrix() * mask\n",
    "\n",
    "        # Compute the scores\n",
    "        self.scores = knn_sim@training.matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2 &ndash; Explicación/documentación\n",
    "\n",
    "En este caso, para realizar las estimaciones de ratings, se plantea un método basado en similitud: un usuario será recomendado items a los cuales otros k usuarios similares a el hayan dado un rating alto. Para calcular esta similitud, se realizará el **coseno** entre dos usuarios desde la matriz de ratings de entrenamiento; por supuesto, no es idea recomendar a un usuario elementos a los cuales ya haya hecho ratings (la similitud de un usuario con el mismo siempre es 1), por lo que todas las diagonales de la matriz deberían ser ignoradas a la hora de calcular los scores.\n",
    "\n",
    "Con la similitud definida, el filtrado colaborativo k-nearest-neighbors (KNN) obtiene los scores de los K usuarios con similitud más alta al actual y computa la recomendación bajo un producto escalar de la matriz:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{r}(u, i) = \\sum_{v \\in K}{sim(u,v) \\times r(v,i)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Filtrado colaborativo: factorización de matrices (2pt)\n",
    "\n",
    "Implementar filtrado colaborativo mediante factorización de matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import datetime, time\n",
    "\n",
    "def plot(train_losses, test_values=[], test_metrics=[]):\n",
    "    f = plt.figure()\n",
    "    plt.plot(range(len(train_losses)), train_losses, color='blue', linewidth=.7, label='Training MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Training error')\n",
    "    ax = plt.gca().twinx()\n",
    "    for m, m_name, color in zip(test_values, test_metrics, ['tab:red', 'darkgreen', 'darkorange', 'darkviolet']):\n",
    "        ax.plot(range(len(m)), m, linewidth=.7, color=color, label=f'Test {m_name}')\n",
    "        plt.ylabel('Test metric')\n",
    "    f.legend(loc='center right', bbox_to_anchor=(0.85, 0.5))\n",
    "\n",
    "def print_progress(rec, start, epoch, error, test_values, test_metrics):\n",
    "    output = f'\\rTraining MF --> Epochs: {epoch+1}  Training error: {error}  '\n",
    "    if test_metrics: output += 'Test metrics: ' \n",
    "    for values, metric in zip(test_values, test_metrics): \n",
    "        val = metric.compute(rec.recommend(metric.cutoff))\n",
    "        output += f'{metric} = {val}  '\n",
    "        values.append(val)\n",
    "    output += f' \\033[94m[{datetime.timedelta(seconds=round(time.time() - start))}]\\033[0m'\n",
    "    print(output, end='              ')\n",
    "        \n",
    "class MF(Recommender):\n",
    "    def __init__(self, training, dim=50, lrate=.001, nepochs=20, test_metrics=[]):\n",
    "        super().__init__(training)\n",
    "        self.scores = self.predict(*self.train(dim, lrate, nepochs, test_metrics))\n",
    "\n",
    "        \n",
    "    def predict(self, p, q):\n",
    "        return (p @ q.T) #* self.mask\n",
    "        \n",
    "    def train(self, dim, lrate, nepochs, test_metrics):\n",
    "        # u = 50, i = 10, k = 3\n",
    "        p = abs(np.random.normal(scale=1/self.training.nusers(), size=(self.training.nusers(), dim))) # 50x3\n",
    "        q = abs(np.random.normal(scale=1/self.training.nitems(), size=(self.training.nitems(), dim))) # 10x3\n",
    "        \n",
    "        ratings = self.training.matrix()\n",
    "        \n",
    "        train_errors, test_values = [], [[] for _ in test_metrics]\n",
    "        start = time.time()\n",
    "        for epoch in range(nepochs):\n",
    "            self.scores = self.predict(p,q)\n",
    "            err = ratings - self.scores # 50x3 @ 3x10 -> 50x10\n",
    "            #p, q = p + lrate * (err @ q), q + lrate * (err.T @ p) # 50x10@10x3, 10x50@50x3\n",
    "            p = p + lrate * (err @ q)\n",
    "            q = q + lrate * (err.T @ p)\n",
    "            \n",
    "            e = (err**2).mean()\n",
    "            train_errors.append(e)\n",
    "            print_progress(self, start, epoch, e, test_values, test_metrics)\n",
    "        print()\n",
    "        # Don't plot for small datasets.\n",
    "        if self.training.nratings() > 1000 : plot(train_errors, test_values, test_metrics)\n",
    "        return p, q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7xYd4hzhukr",
    "tags": []
   },
   "source": [
    "### Ejercicio 3 &ndash; Explicación/documentación\n",
    "\n",
    "Otra forma de poder realizar recomendaciones a los usuarios se centra sobre los facotres latentes $f \\in F$, esto es, representar tanto a los usuarios como items según un vector de características $u^F$ y $i^F$, espacios pequeños que puedan representar sus gustos y sean más efectivos de calcular que KNN. De esta forma, la recomendación $\\hat{r}(u,i)$ pasa a ser simplemente $u \\times i$. Lo que restaría hacer es obtener estas representaciones de usuarios e items, es decir, crear los parámetros del modelo.\n",
    "\n",
    "Esto lo haremos con entrenamiento basado en el descenso por gradiente, con la idea de minimizar el error cuadrático $({r(u,i) - u \\times i})^2$ para cada usuario e item. Para hacerlo sobre todas las combinaciones usuario-item a la vez, podemos pasar de vectores $u^k$, $i^k$ directamente a matrices $p^{|U| \\times k}$, $q^{|I| \\times k}$, de manera que el algoritmo se vería como el siguiente:\n",
    "```\n",
    "for n from 0 to nepochs\n",
    "    e = r(u,i) - p * q.T\n",
    "    p, q = p + α (e * q), q + α (e.T * p)\n",
    "```\n",
    "Es importante notar que, en python, existe una sutíl diferencia en los resultados si se calculan p y q en la misma sentencia o por separado. En la solución A (presentado en este pseudocódigo), utiliza los valores de $p$ y $q$ de la época de entrenamiento actual en ambas asignaciones: $p^i$, $q^i$, $i \\in$ $n_{epochs}$. En la solución B (dentro del ejercicio), el cálculo de $q$ se realiza utilizando al $p$ de la siguiente época (que fue asignado en la instrucción anterior): $p^{i+1}$. Esto puede dar resultados diferentes con respecto a las ejecuciones de test provistas, por lo que si bien la solución A es \"correcta\", optamos por utilizar la solución B para cuadrar resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVzsIg0Zev7a",
    "tags": []
   },
   "source": [
    "## Ejercicio 4: Evaluación (2pt)\n",
    "\n",
    "Se desarrollarán clases que permitan calcular métricas para evaluar y comparar el acierto de los recomendadores: se implementarán **precisión** y **recall**. \n",
    "\n",
    "Como resumen de este bloque, se incluirá una *tabla con los valores de las métricas* (dos columnas) más el tiempo de ejecución (una columna más) sobre todos los algoritmos implementados (filas), al menos para el conjunto de datos de <ins>MovieLens 1M</ins>. En el caso de ser capaces de procesar un conjunto de datos más grande, se documentará el tamaño en RAM de la matriz de ratings.\n",
    "\n",
    "<!-- Opcionalmente, se podrán implementar otras métricas a elección del estudiante (nDCG, etc.), cuya prueba se incluirá en la función `student_test()` del ejercicio 4 (\"ampliaciones\"). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VqSKneeSe2bN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Metric():\n",
    "    def __init__(self, test, cutoff):\n",
    "        self.test = test\n",
    "        self.cutoff = cutoff\n",
    "\n",
    "    def __repr__(self):\n",
    "        return type(self).__name__ + ('@' + str(self.cutoff) if self.cutoff != np.inf else '')\n",
    "\n",
    "class Precision(Metric):\n",
    "    def __init__(self, test, cutoff=np.inf, threshold=1):\n",
    "        super().__init__(test, cutoff)\n",
    "        # This is the threshold of the score to be considered either relevant or not\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def compute(self, recommendation):\n",
    "        k_recommendations = recommendation.ranked_iidx()[:,0:self.cutoff]\n",
    "        \n",
    "        x = np.take_along_axis(recommendation.score_matrix(), k_recommendations, axis=1)\n",
    "        y = np.take_along_axis(self.test.matrix(), k_recommendations, axis=1)\n",
    "        \n",
    "        relevant_m = (x >= 0) * (y >= self.threshold)\n",
    "\n",
    "        return (np.sum(relevant_m, axis=1) / self.cutoff).mean()\n",
    "        \n",
    "class Recall(Metric):\n",
    "    def __init__(self, test, cutoff=np.inf, threshold=1):\n",
    "        super().__init__(test, cutoff)\n",
    "        self.threshold = threshold\n",
    "        self.individual_relevant = np.sum(test.matrix() >= threshold, axis=1)\n",
    "        self.individual_relevant[self.individual_relevant == 0] = 1\n",
    "        \n",
    "    def compute(self, recommendation):\n",
    "        k_recommendations = recommendation.ranked_iidx()[:,0:self.cutoff]\n",
    "        \n",
    "        x = np.take_along_axis(recommendation.score_matrix(), k_recommendations, axis=1)\n",
    "        y = np.take_along_axis(self.test.matrix(), k_recommendations, axis=1)\n",
    "        \n",
    "        relevant_m = (x >= 0) * (y >= self.threshold)\n",
    "\n",
    "        return (np.divide(np.sum(relevant_m, axis=1), self.individual_relevant)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJDzjUp-hwNZ",
    "tags": []
   },
   "source": [
    "### Ejercicio 4 &ndash; Explicación/documentación\n",
    "\n",
    "Para poder evaluar los algoritmos de ranking implementados anteriormente, utilizamos dos medidas ya presentadas en los sistemas de information retrieval:\n",
    "- Precision: El número de documentos relevantes devueltos, sobre el número de documentos *total devuelto*.\n",
    "- Recall: El número de documentos relevantes devueltos, sobre el número de documentos *relevantes totales*.\n",
    "\n",
    "Para los *sistemas de recomendación*, la 'relevancia' de un documento refiere a los propios ratings de usuarios sobre items: Aquellos items cuyo rating de usuario $r(u,i)$ sea superior a cierto threshold serán considerados relevantes, y el resto no.\n",
    "\n",
    "Por tanto, para ambas métricas, se hace uso de dos matrices *x*, *y*, que actúan como representación de las dos condiciones a cumplir: el conjunto de scores de cada usuario (hasta cutoff elementos), y aquellos que cumplan el threshold esperado. Ambas métricas son obtenidas de realizar operaciones básicas sobre el resultado obtenido de multiplicar dichas matrices, que pasarán a contener valores binarios:\n",
    "\n",
    "- Precision: media de unos por fila entre el cutoff. `(row.count(1) / cutoff).mean()`\n",
    "- Recall: media de unos por fila entre total relevante por usuario. `(row.count(1) / self.nrelevant).mean()`\n",
    "\n",
    "Para la siguiente tabla de métricas, el campo \"tiempo de ejecución\" también tendremos en cuenta el tiepo que se tarda en construir las matrices de recomendaciones, puesto que sino todos los tiempos serán 00:00.\n",
    "\n",
    "Tabla de resumen **MovieLens 1M**. \n",
    "\n",
    "||Precision@K|Recall@K|Tiempo de ejecución\n",
    "|-|:-:|:-:|:-:\n",
    "|**RandomRecommender**|0.005397350993377485|0.002749305863731276|0:00:01\n",
    "|**MayorityRecommender**|0.15114238410596026|0.09141827174714759|0:00:00\n",
    "|**AverageRecommender**|0.009701986754966889|0.006141799629131731|0:00:00\n",
    "|**UserKNNRecommender**|0.23014900662251653|0.17895309718471897|0:00:15\n",
    "|**MFRecommender**|0.27764900662251657|0.1927300021391895|0:02:35\n",
    "|**ItemKNNRecommender**|0.23639072847682122|0.1927300021391895|0:00:20\n",
    "|**NormalizedKNNRecommender**|0.27764900662251657|0.1927300021391895|0:07:50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpXHr18Cdl2Q",
    "tags": []
   },
   "source": [
    "## Ejercicio 5: Ampliaciones (2pt)\n",
    "\n",
    "Elegir uno de los siguientes ejercicios:\n",
    "\n",
    "* Implementar dos variantes de kNN a elección del estudiante, por ejemplo: kNN normalizado, vecinos próximos orientado a item, similitud de Pearson, kNN centrado en la media. Indicación: para kNN normalizado el algoritmo exigirá un mínimo de ratings de vecinos para aceptar recomendar un item (con ello se mejora el acierto de la recomendación, de forma similar a la recomendación por rating promedio).\n",
    "* Crear una implementación de las estructuras de ratings con matrices dispersas, de forma que sea posible generar recomendaciones sobre conjuntos de datos más grandes, tales como [MovieLens 10M](https://grouplens.org/datasets/movielens/10m) y [MovieLens 25M](https://grouplens.org/datasets/movielens/25m).\n",
    "\n",
    "Para probar las implementaciones deberá completarse la función `student_test()` para ilustrar la ejecución de las variantes adicionales, y se incluirán las filas que correspondan en la tabla del apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MOfT2yZGpMNi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Código aquí: clases, funciones...\n",
    "class CosineItemSimilarity:\n",
    "    def __init__(self, training):\n",
    "        # Compute the dot similarity (i * j) of all users\n",
    "        # The diagonal is filled with i^2 values for every item\n",
    "        dot_matrix = training.matrix().T@(training.matrix())\n",
    "\n",
    "        # Get a vector of item mods, set to 1 when no ratings are given\n",
    "        mods = np.sqrt(np.diag(dot_matrix))\n",
    "        mods[mods==0] = 1\n",
    "\n",
    "        # Create a similarity cosine matrix between items, and set our\n",
    "        # own similarity to 0\n",
    "        self.sim = ((dot_matrix / mods).T / mods).T\n",
    "        np.fill_diagonal(self.sim, 0)\n",
    "\n",
    "    def sim_matrix(self):\n",
    "        return self.sim\n",
    "\n",
    "class ItemKNNRecommender(Recommender):\n",
    "    def __init__(self, training, sim, k):\n",
    "        super().__init__(training)\n",
    "\n",
    "        # Get the k closest neighbours\n",
    "        knn = top_positions_per_row(sim.sim_matrix(), k)\n",
    "\n",
    "        # Create a mask where k neighbours = 1, else 0\n",
    "        mask = np.zeros_like(sim.sim_matrix())\n",
    "        mask[np.arange(mask.shape[0]), knn.T] = 1\n",
    "\n",
    "        # Mask sim matrix\n",
    "        knn_sim = sim.sim_matrix() * mask\n",
    "        \n",
    "        # Compute the scores\n",
    "        self.scores = (knn_sim @ training.matrix().T).T\n",
    "        \n",
    "class NormalizedKNNRecommender(Recommender):\n",
    "    def __init__(self, training, sim, k, minr=0):\n",
    "        super().__init__(training)\n",
    "\n",
    "        # Get the k closest neighbours\n",
    "        knn = top_positions_per_row(sim.sim_matrix(), k)\n",
    "\n",
    "        # Create a mask where k neighbours = 1, else 0\n",
    "        mask = np.zeros_like(sim.sim_matrix())\n",
    "        mask[np.arange(mask.shape[0]), knn.T] = 1\n",
    "\n",
    "        # Mask sim matrix\n",
    "        knn_sim = sim.sim_matrix() * mask\n",
    "\n",
    "        # Create a mask where a score is True if at least \n",
    "        # minr neighbours rated the item, else False\n",
    "        mask = ((knn_sim > 0)*1)@((training.matrix()>0)*1) >= minr\n",
    "\n",
    "        # Compute the scores\n",
    "        norm = knn_sim@(training.matrix()>0)\n",
    "        norm[norm==0] = 1\n",
    "        \n",
    "        self.scores = ((knn_sim@training.matrix()) / norm) * mask\n",
    "\n",
    "def student_test(ratings_file=\"data/toy1.csv\", sep=\",\", k=4, topn=4, cutoff=4, threshold=1, minr=0):\n",
    "    np.random.seed(0)\n",
    "    start = time.time()\n",
    "    ratings = Ratings(ratings_file, sep)\n",
    "    train, test = ratings.random_split(0.8)\n",
    "    metrics = [Precision(test, cutoff=cutoff, threshold=threshold), Recall(test, cutoff=cutoff, threshold=threshold)]\n",
    "    \n",
    "    print('\\n=========================\\nExtra testing checking')\n",
    "    ratings = Ratings(ratings_file, sep)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    print('Creating item cosine similarity')\n",
    "    sim = CosineItemSimilarity(train)\n",
    "    start = timer(start)\n",
    "    print('Creating kNN recommender')\n",
    "    knn = ItemKNNRecommender(train, sim, k)\n",
    "    start = timer(start)\n",
    "    run_recommender(knn, metrics, topn)\n",
    "    timer(start)\n",
    "\n",
    "    print('-------------------------')\n",
    "    print('Creating user cosine similarity')\n",
    "    sim = CosineUserSimilarity(train)\n",
    "    start = timer(start)\n",
    "    print('Creating kNN average recommender')\n",
    "    knn = NormalizedKNNRecommender(train, sim, k, minr)\n",
    "    start = timer(start)\n",
    "    run_recommender(knn, metrics, topn)\n",
    "    timer(start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucORmwfCh4Um",
    "tags": []
   },
   "source": [
    "### Ejercicio 5 &ndash; Explicación/documentación\n",
    "\n",
    "Existen varios métodos de knn alternativos al basado en el usuario. En este caso, optamos por implementar dos: KNN basado en *items* y KNN *normalizado*.\n",
    "\n",
    "Para el primero de los casos, el **KNN basado en items**, se debe transponer la forma de pensar en el problema. En lugar de hacer recomendaciones de usuario basados en ratings de otros usuarios similares, se ven los propios items a los que el usuario ya haya valorado; y se calcula la *similitud entre items*. En este caso, la similitud también viene dada en forma de coseno con respecto a los 'vectores item': los ratings de usuario sobre cada item, es decir, las *columnas*.\n",
    "\n",
    "En términos de código, lo único que cambia a la hora de realizar la clase `CosineUserSimilarity` es el orden de multiplicación de matrices: se multiplica la matriz de entrenamiento transpuesta con la original, en lugar de *viceversa*. Ya que la matriz de similitud resultante será de orden $|I|$ en lugar de orden $|U|$, es necesario transponerla nuevamente para operar con la matriz de entrenamiento $|U| \\times |I|$, y luego transponer el resultado nuevamente para dar un score con las dimensiones originales.\n",
    "\n",
    "El segundo de los casos, el **KNN normalizado**, es una extensión del algoritmo original de KNN basado en usuarios; lo único que se debe hacer es dividir por la suma de las similitudes para obtener un ranking válido (en nuestro caso, entre 1 y 5). Eso implica que no se necesita cambiar la clase original que calcula similitudes, sino que solo el modo de computar scores preliminares. La forma de calcular estos factores de normalización es realizar otro producto de matrices, tratando los ratings como valores booleanos ($\\forall$ $i,j;$ $\\exists$ $r(i,j) > 0$?); de esta forma, se elige que similitudes usar y cuales no.\n",
    "\n",
    "Luego, para poder dar mayor fiabilidad a este tipo de ranking, es necesario que se tenga un número de rankings mínimo por parte de los vecinos. Es decir, si solo existe un vecino dentro de los k más proximos que haya dado rating de 5 a un item, es muy probable que este sea la primera recomendación. Para garantizar dicha condición se usa una segunda máscara:\n",
    "\n",
    "- `((knn_sim > 0)*1)@((training.matrix()>0)*1) >= minr`\n",
    "\n",
    "Esta, a diferencia de un `np.count_nonzeros()` por columnas, cubre un caso particular que la anterior no. A la hora de contar ratings, la máscara original (i.e., la del Average Recommender) también tiene en cuenta el rating propio para el mínimo de ratings; esto puede dar un caso donde el número de ratings vecinos es $minr - 1$, y que con el rating de usuario dicha métrica se de como válida (en el caso límite de minr=1, implica también una división por cero). Las transformaciones aplicadas en la matriz de similitud y entrenamiento computan, en cada valor resultante, cuáles de los k-vecinos han valorado el item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Celda de prueba\n",
    "\n",
    "Descarga los ficheros de datos y coloca sus contenidos en una carpeta **data** en el mismo directorio que este *notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Testing toy 1 dataset\n",
      "\u001b[34mReading the data at 19:24:20...\u001b[0m\n",
      "Ratings matrix takes 0.0 MB in RAM\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing the ratings data structures\n",
      "11 ratings by 4 users on 5 items\n",
      "Ratings of user v: {'b': 4.0, 'c': 5.0, 'd': 3.0}\n",
      "Ratings of item b: {'v': 4.0, 'x': 2.0, 'y': 4.0}\n",
      "-------------------------\n",
      "Testing RandomRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User v -> <a:0.9786 e:0.1183>\n",
      "    User x -> <c:0.9447 d:0.5218>\n",
      "    User y -> <d:0.5684 e:0.0188>\n",
      "    User z -> <e:0.6818 a:0.6176 c:0.6169 b:0.6121>\n",
      "Precision@4 = 0.0625\n",
      "Recall@4 = 0.25\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing MajorityRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User v -> <a:1 e:1>\n",
      "    User x -> <c:2 d:1>\n",
      "    User y -> <d:1 e:1>\n",
      "    User z -> <b:2 c:2 a:1 e:1>\n",
      "Precision@4 = 0.0625\n",
      "Recall@4 = 0.25\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing AverageRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User v -> <a:3>\n",
      "    User x -> <c:4.5 d:4>\n",
      "    User y -> <d:4>\n",
      "    User z -> <c:4.5 b:3.3333 a:3>\n",
      "Precision@4 = 0.0625\n",
      "Recall@4 = 0.25\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Creating user cosine similarity\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "Creating kNN recommender\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "Testing UserKNNRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User v -> <a:1.7295 e:0.6746>\n",
      "    User x -> <c:2.1927 d:0.506>\n",
      "    User y -> <d:2.6588 e:1.3494>\n",
      "    User z -> <c:2.1213 b:1.6971>\n",
      "Precision@4 = 0.0625\n",
      "Recall@4 = 0.25\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Creating MF recommender\n",
      "\r",
      "Training MF --> Epochs: 1  Training error: 7.034387313244215  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 2  Training error: 7.028116207732554  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 3  Training error: 7.021813645751315  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 4  Training error: 7.015479418874686  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 5  Training error: 7.009113320386417  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 6  Training error: 7.0027151453112  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 7  Training error: 6.996284690446548  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 8  Training error: 6.989821754395125  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 9  Training error: 6.983326137597558  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 10  Training error: 6.976797642365715  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 11  Training error: 6.970236072916444  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 12  Training error: 6.963641235405776  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 13  Training error: 6.95701293796358  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 14  Training error: 6.9503509907286825  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 15  Training error: 6.9436552058844185  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 16  Training error: 6.9369253976946466  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 17  Training error: 6.930161382540199  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 18  Training error: 6.923362978955744  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 19  Training error: 6.916530007667129  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 20  Training error: 6.909662291629101  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 21  Training error: 6.902759656063472  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 22  Training error: 6.895821928497696  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 23  Training error: 6.888848938803855  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 24  Training error: 6.8818405192380485  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 25  Training error: 6.87479650448017  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 26  Training error: 6.867716731674096  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 27  Training error: 6.860601040468239  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 28  Training error: 6.853449273056482  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 29  Training error: 6.846261274219482  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 30  Training error: 6.839036891366346  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 31  Training error: 6.831775974576648  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 32  Training error: 6.824478376642785  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 33  Training error: 6.817143953112696  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 34  Training error: 6.809772562332888  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 35  Training error: 6.802364065491784  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 36  Training error: 6.794918326663392  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 37  Training error: 6.787435212851261  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 38  Training error: 6.779914594032744  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 39  Training error: 6.772356343203522  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 40  Training error: 6.764760336422417  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 41  Training error: 6.757126452856452  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 42  Training error: 6.749454574826167  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 43  Training error: 6.741744587851175  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 44  Training error: 6.733996380695918  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 45  Training error: 6.726209845415677  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 46  Training error: 6.718384877402751  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 47  Training error: 6.7105213754328386  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 48  Training error: 6.7026192417115995  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 49  Training error: 6.694678381921349  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 50  Training error: 6.6866987052679505  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 51  Training error: 6.678680124527794  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 52  Training error: 6.670622556094928  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 53  Training error: 6.662525920028277  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 54  Training error: 6.654390140098968  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 55  Training error: 6.6462151438377095  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 56  Training error: 6.638000862582258  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 57  Training error: 6.629747231524904  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 58  Training error: 6.621454189759997  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 59  Training error: 6.613121680331486  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 60  Training error: 6.604749650280444  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 61  Training error: 6.596338050692578  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 62  Training error: 6.587886836745691  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 63  Training error: 6.579395967757091  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 64  Training error: 6.570865407230924  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 65  Training error: 6.5622951229054065  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 66  Training error: 6.553685086799945  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 67  Training error: 6.545035275262132  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 68  Training error: 6.536345669014565  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 69  Training error: 6.527616253201524  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 70  Training error: 6.518847017435434  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 71  Training error: 6.510037955843108  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 72  Training error: 6.501189067111794  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 73  Training error: 6.49230035453491  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 74  Training error: 6.483371826057555  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 75  Training error: 6.474403494321685  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 76  Training error: 6.465395376710984  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 77  Training error: 6.456347495395396  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 78  Training error: 6.447259877375269  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 79  Training error: 6.438132554525147  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 80  Training error: 6.428965563637114  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 81  Training error: 6.4197589464637215  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 82  Training error: 6.41051274976046  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 83  Training error: 6.401227025327735  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 84  Training error: 6.3919018300523485  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 85  Training error: 6.382537225948441  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 86  Training error: 6.373133280197879  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 87  Training error: 6.363690065190076  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 88  Training error: 6.354207658561174  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 89  Training error: 6.344686143232635  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 90  Training error: 6.335125607449146  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 91  Training error: 6.32552614481586  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 92  Training error: 6.315887854334909  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 93  Training error: 6.30621084044121  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 94  Training error: 6.296495213037491  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 95  Training error: 6.286741087528531  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 96  Training error: 6.276948584854603  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 97  Training error: 6.2671178315240645  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 98  Training error: 6.257248959645077  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 99  Training error: 6.247342106956456  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 100  Training error: 6.237397416857581  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 101  Training error: 6.227415038437366  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 102  Training error: 6.217395126502256  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 103  Training error: 6.207337841603229  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 104  Training error: 6.1972433500617665  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 105  Training error: 6.187111823994774  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 106  Training error: 6.176943441338414  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 107  Training error: 6.166738385870841  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 108  Training error: 6.156496847233791  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 109  Training error: 6.146219020953028  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 110  Training error: 6.13590510845758  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 111  Training error: 6.125555317097783  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 112  Training error: 6.115169860162064  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 113  Training error: 6.104748956892481  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 114  Training error: 6.094292832498935  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 115  Training error: 6.0838017181721025  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 116  Training error: 6.073275851094998  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 117  Training error: 6.0627154744531655  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 118  Training error: 6.052120837443488  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 119  Training error: 6.0414921952815686  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 120  Training error: 6.030829809207655  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 121  Training error: 6.020133946491116  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 122  Training error: 6.009404880433397  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 123  Training error: 5.998642890369487  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 124  Training error: 5.987848261667809  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 125  Training error: 5.977021285728566  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 126  Training error: 5.966162259980498  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 127  Training error: 5.955271487876027  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 128  Training error: 5.944349278884755  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 129  Training error: 5.933395948485324  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 130  Training error: 5.922411818155593  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 131  Training error: 5.911397215361125  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 132  Training error: 5.900352473541945  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 133  Training error: 5.889277932097576  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 134  Training error: 5.878173936370311  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 135  Training error: 5.867040837626722  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 136  Training error: 5.855878993037362  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 137  Training error: 5.844688765654673  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 138  Training error: 5.833470524389071  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 139  Training error: 5.822224643983178  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 140  Training error: 5.810951504984209  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 141  Training error: 5.799651493714486  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 142  Training error: 5.788325002240069  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 143  Training error: 5.776972428337498  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 144  Training error: 5.76559417545861  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 145  Training error: 5.754190652693455  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 146  Training error: 5.742762274731273  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 147  Training error: 5.731309461819528  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 148  Training error: 5.719832639721007  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 149  Training error: 5.708332239668947  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 150  Training error: 5.696808698320213  Test metrics: Precision@4 = 0.0625  Recall@4 = 0.25   \u001b[94m[0:00:00]\u001b[0m              \n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "Testing MF (top 4)\n",
      "Four example recommendations:\n",
      "    User v -> <e:0.4953 a:0.4616>\n",
      "    User x -> <c:0.6584 d:0.3735>\n",
      "    User y -> <d:0.5324 e:0.5185>\n",
      "    User z -> <c:0.5105 b:0.4079 e:0.2866 a:0.2851>\n",
      "Precision@4 = 0.0625\n",
      "Recall@4 = 0.25\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "=========================\n",
      "Testing toy 2 dataset\n",
      "\u001b[34mReading the data at 19:24:20...\u001b[0m\n",
      "Ratings matrix takes 0.0 MB in RAM\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing the ratings data structures\n",
      "22 ratings by 5 users on 10 items\n",
      "Ratings of user 1: {1: 1.0, 5: 5.0, 7: 2.0, 10: 5.0}\n",
      "Ratings of item 2: {2: 2.0, 4: 2.0}\n",
      "-------------------------\n",
      "Testing RandomRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User 1 -> <4:0.9988 2:0.9195 6:0.8681 3:0.7142>\n",
      "    User 2 -> <9:0.9755 8:0.8664 10:0.8558 1:0.8073>\n",
      "    User 3 -> <9:0.7937 3:0.73 2:0.36 7:0.2>\n",
      "    User 4 -> <9:0.9342 3:0.7044 6:0.6215 1:0.3454>\n",
      "Precision@4 = 0.1\n",
      "Recall@4 = 0.16666666666666666\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing MajorityRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User 1 -> <3:1 4:1 6:1>\n",
      "    User 2 -> <5:2 3:1 4:1 6:1>\n",
      "    User 3 -> <3:1 4:1 6:1 7:1>\n",
      "    User 4 -> <5:2 3:1 6:1>\n",
      "Precision@4 = 0.15\n",
      "Recall@4 = 0.2333333333333333\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing AverageRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User 1 -> <2:2>\n",
      "    User 2 -> <5:4.5 10:3.3333 1:2>\n",
      "    User 3 -> <7:2.6667 1:2 2:2>\n",
      "    User 4 -> <5:4.5 1:2>\n",
      "Precision@4 = 0.1\n",
      "Recall@4 = 0.3\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Creating user cosine similarity\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "Creating kNN recommender\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "Testing UserKNNRecommender (top 4)\n",
      "Four example recommendations:\n",
      "    User 1 -> <4:1.6543 2:1.1625 8:0.9926 6:0.286>\n",
      "    User 2 -> <10:1.9756 5:1.252 4:1.2061 8:0.7237>\n",
      "    User 3 -> <7:2.0027 4:0.9682 1:0.9045 8:0.5809>\n",
      "    User 4 -> <5:2.4289 1:0.3309>\n",
      "Precision@4 = 0.15\n",
      "Recall@4 = 0.36666666666666664\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Creating MF recommender\n",
      "\r",
      "Training MF --> Epochs: 1  Training error: 3.928720159681153  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 2  Training error: 3.927472540776626  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 3  Training error: 3.9262185789317288  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 4  Training error: 3.9249582075478795  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 5  Training error: 3.9236913599789016  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 6  Training error: 3.922417969531746  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 7  Training error: 3.921137969467274  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 8  Training error: 3.9198512930011344  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 9  Training error: 3.918557873304715  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 10  Training error: 3.917257643506168  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 11  Training error: 3.915950536691531  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 12  Training error: 3.9146364859059055  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 13  Training error: 3.913315424154751  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 14  Training error: 3.911987284405231  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 15  Training error: 3.9106519995876585  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 16  Training error: 3.9093095025970275  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 17  Training error: 3.907959726294622  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 18  Training error: 3.9066026035097132  Test metrics: Precision@4 = 0.2  Recall@4 = 0.3333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 19  Training error: 3.90523806704135  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 20  Training error: 3.9038660496602273  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 21  Training error: 3.9024864841106517  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 22  Training error: 3.9010993031125865  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 23  Training error: 3.8997044393637967  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 24  Training error: 3.898301825542079  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 25  Training error: 3.896891394307581  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 26  Training error: 3.895473078305218  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 27  Training error: 3.894046810167183  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 28  Training error: 3.892612522515541  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 29  Training error: 3.8911701479649303  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 30  Training error: 3.8897196191253496  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 31  Training error: 3.888260868605047  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 32  Training error: 3.886793829013504  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 33  Training error: 3.885318432964513  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 34  Training error: 3.8838346130793626  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 35  Training error: 3.8823423019901067  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 36  Training error: 3.8808414323429563  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 37  Training error: 3.8793319368017465  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 38  Training error: 3.8778137480515262  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 39  Training error: 3.876286798802233  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 40  Training error: 3.8747510217924868  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 41  Training error: 3.873206349793472  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 42  Training error: 3.8716527156129406  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 43  Training error: 3.870090052099302  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 44  Training error: 3.868518292145836  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 45  Training error: 3.8669373686949986  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 46  Training error: 3.86534721474285  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 47  Training error: 3.8637477633435706  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 48  Training error: 3.8621389476141115  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 49  Training error: 3.8605207007389293  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 50  Training error: 3.85889295597485  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 51  Training error: 3.8572556466560326  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 52  Training error: 3.8556087061990514  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 53  Training error: 3.853952068108086  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 54  Training error: 3.8522856659802276  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 55  Training error: 3.8506094335108982  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 56  Training error: 3.8489233044993796  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 57  Training error: 3.847227212854466  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 58  Training error: 3.845521092600226  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 59  Training error: 3.843804877881881  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 60  Training error: 3.8420785029718036  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 61  Training error: 3.8403419022756298  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 62  Training error: 3.8385950103384947  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 63  Training error: 3.836837761851374  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 64  Training error: 3.835070091657562  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 65  Training error: 3.833291934759258  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 66  Training error: 3.83150322632427  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 67  Training error: 3.8297039016928487  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 68  Training error: 3.827893896384639  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 69  Training error: 3.8260731461057396  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 70  Training error: 3.82424158675591  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 71  Training error: 3.822399154435875  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 72  Training error: 3.820545785454767  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 73  Training error: 3.8186814163376828  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 74  Training error: 3.816805983833367  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 75  Training error: 3.814919424922017  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 76  Training error: 3.813021676823214  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 77  Training error: 3.811112677003976  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 78  Training error: 3.8091923631869316  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 79  Training error: 3.807260673358625  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 80  Training error: 3.8053175457779402  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 81  Training error: 3.8033629189846465  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 82  Training error: 3.8013967318080777  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 83  Training error: 3.799418923375931  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 84  Training error: 3.797429433123183  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 85  Training error: 3.79542820080114  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 86  Training error: 3.7934151664866107  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 87  Training error: 3.7913902705912004  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 88  Training error: 3.789353453870731  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 89  Training error: 3.787304657434782  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 90  Training error: 3.785243822756358  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 91  Training error: 3.7831708916816793  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 92  Training error: 3.7810858064400943  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 93  Training error: 3.7789885096541163  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 94  Training error: 3.7768789443495763  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 95  Training error: 3.77475705396591  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 96  Training error: 3.7726227823665535  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 97  Training error: 3.770476073849464  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 98  Training error: 3.7683168731577634  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 99  Training error: 3.7661451254905005  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 100  Training error: 3.7639607765135286  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 101  Training error: 3.7617637723705046  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 102  Training error: 3.7595540596940022  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 103  Training error: 3.7573315856167455  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 104  Training error: 3.7550962977829556  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 105  Training error: 3.7528481443598105  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 106  Training error: 3.750587074049025  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 107  Training error: 3.7483130360985304  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 108  Training error: 3.746025980314282  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 109  Training error: 3.7437258570721617  Test metrics: Precision@4 = 0.1  Recall@4 = 0.16666666666666666   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 110  Training error: 3.7414126173299973  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 111  Training error: 3.739086212639691  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 112  Training error: 3.7367465951594494  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 113  Training error: 3.7343937176661166  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 114  Training error: 3.7320275335676185  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 115  Training error: 3.729647996915503  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 116  Training error: 3.7272550624175778  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 117  Training error: 3.724848685450656  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 118  Training error: 3.7224288220733888  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 119  Training error: 3.7199954290391952  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 120  Training error: 3.7175484638092886  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 121  Training error: 3.71508788456579  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 122  Training error: 3.7126136502249323  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 123  Training error: 3.710125720450348  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 124  Training error: 3.707624055666445  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 125  Training error: 3.7051086170718643  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 126  Training error: 3.7025793666530156  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 127  Training error: 3.700036267197685  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 128  Training error: 3.6974792823087355  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 129  Training error: 3.694908376417857  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 130  Training error: 3.692323514799402  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 131  Training error: 3.6897246635842773  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 132  Training error: 3.6871117897739127  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 133  Training error: 3.6844848612542758  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 134  Training error: 3.681843846809959  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 135  Training error: 3.6791887161383077  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 136  Training error: 3.6765194398636134  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 137  Training error: 3.673835989551346  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 138  Training error: 3.6711383377224367  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 139  Training error: 3.668426457867598  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 140  Training error: 3.665700324461688  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 141  Training error: 3.6629599129781085  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 142  Training error: 3.660205199903225  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 143  Training error: 3.6574361627508285  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 144  Training error: 3.6546527800766127  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 145  Training error: 3.651855031492665  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 146  Training error: 3.649042897681994  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 147  Training error: 3.646216360413041  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 148  Training error: 3.6433754025542195  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 149  Training error: 3.64052000808845  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \r",
      "Training MF --> Epochs: 150  Training error: 3.637650162127692  Test metrics: Precision@4 = 0.15  Recall@4 = 0.2333333333333333   \u001b[94m[0:00:00]\u001b[0m              \n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "Testing MF (top 4)\n",
      "Four example recommendations:\n",
      "    User 1 -> <2:0.2271 6:0.1656 4:0.16 3:0.1519>\n",
      "    User 2 -> <5:0.2575 10:0.2175 4:0.1515 6:0.1484>\n",
      "    User 3 -> <2:0.2136 3:0.1871 7:0.1762 6:0.1679>\n",
      "    User 4 -> <5:0.3381 6:0.2102 3:0.1824 1:0.1456>\n",
      "Precision@4 = 0.15\n",
      "Recall@4 = 0.2333333333333333\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "=========================\n",
      "Testing MovieLens '1 million' dataset\n",
      "\u001b[34mReading the data at 19:24:20...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6847/1864745669.py:15: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings_df = pd.read_csv(file, sep=sep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings matrix takes 170.8 MB in RAM\n",
      "\u001b[34m--> elapsed time: 0:00:05 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing the ratings data structures\n",
      "1,000,209 ratings by 6,040 users on 3,706 items\n",
      "Ratings of user 200: {8: 3.0, 170: 5.0, 940: 4.0, 1059: 5.0, 1127: 4.0, 1441: 4.0, 1605: 1.0, 1911: 2.0, 2041: 5.0, 2355: 3.0, 2555: 2.0, 2572: 5.0, 2599: 3.0, 2605: 2.0, 2683: 3.0, 2694: 5.0, 2699: 4.0, 2706: 2.0, 2759: 2.0, 2770: 2.0, 2779: 2.0, 2827: 3.0, 2997: 4.0, 3051: 5.0, 3408: 5.0, 3751: 4.0}\n",
      "Ratings of item 1000: {474: 5.0, 1733: 2.0, 2820: 3.0, 3032: 4.0, 3193: 2.0, 3197: 3.0, 3224: 4.0, 3391: 3.0, 3507: 4.0, 3526: 3.0, 3644: 5.0, 3829: 4.0, 3868: 4.0, 3942: 1.0, 4088: 3.0, 4139: 4.0, 4732: 3.0, 5426: 2.0, 5682: 1.0, 5916: 1.0}\n",
      "-------------------------\n",
      "Testing RandomRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <3627:0.9996 3007:0.9991 1103:0.999 2399:0.9989 69:0.9988 900:0.9987 2750:0.9987 154:0.9986 2478:0.9985 1928:0.9983>\n",
      "    User 2 -> <2417:1 187:0.9995 3239:0.9994 1850:0.9986 1575:0.9984 1440:0.9984 3218:0.9984 3083:0.9983 465:0.9974 2165:0.9971>\n",
      "    User 3 -> <840:0.9999 3784:0.9997 3586:0.9996 278:0.999 2640:0.9988 3569:0.9985 3223:0.9984 150:0.9982 1485:0.998 3699:0.9978>\n",
      "    User 4 -> <2759:0.9997 3364:0.9996 2336:0.9996 2302:0.9993 1251:0.9992 553:0.9989 1659:0.9986 3206:0.998 1657:0.9974 1391:0.9974>\n",
      "Precision@10 = 0.005397350993377485\n",
      "Recall@10 = 0.002749305863731276\n",
      "\u001b[34m--> elapsed time: 0:00:01 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing MajorityRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <2858:2272 1196:2008 593:1803 1198:1776 2571:1754 1210:1716 608:1656 318:1623 589:1616 858:1592>\n",
      "    User 2 -> <260:2094 2762:1768 608:1656 527:1653 318:1623 858:1592 1197:1534 1617:1516 1270:1507 2997:1426>\n",
      "    User 3 -> <1196:2008 593:1803 2028:1803 1198:1776 2762:1768 2571:1754 608:1656 527:1653 318:1623 589:1616>\n",
      "    User 4 -> <2858:2272 260:2094 593:1803 2762:1768 2571:1754 608:1656 527:1653 318:1623 589:1616 858:1592>\n",
      "Precision@10 = 0.15114238410596026\n",
      "Recall@10 = 0.09141827174714759\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Testing AverageRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <787:5 1117:4.75 53:4.7143 2503:4.6667 2538:4.6667 3232:4.6667 2905:4.6296 1780:4.6 2019:4.5608 318:4.5469>\n",
      "    User 2 -> <787:5 1117:4.75 53:4.7143 2503:4.6667 2538:4.6667 3232:4.6667 2905:4.6296 1780:4.6 2019:4.5608 318:4.5469>\n",
      "    User 3 -> <787:5 1117:4.75 53:4.7143 2503:4.6667 2538:4.6667 3232:4.6667 2905:4.6296 1780:4.6 2019:4.5608 318:4.5469>\n",
      "    User 4 -> <787:5 1117:4.75 53:4.7143 2503:4.6667 2538:4.6667 3232:4.6667 2905:4.6296 1780:4.6 2019:4.5608 318:4.5469>\n",
      "Precision@10 = 0.009701986754966889\n",
      "Recall@10 = 0.006141799629131731\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Creating user cosine similarity\n",
      "\u001b[34m--> elapsed time: 0:00:05 <--\u001b[0m\n",
      "Creating kNN recommender\n",
      "\u001b[34m--> elapsed time: 0:00:10 <--\u001b[0m\n",
      "Testing UserKNNRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <1022:10.7132 2081:9.7869 2085:9.0631 588:8.834 1282:7.1751 2096:5.9198 1196:5.6073 1584:5.5885 596:5.4641 1721:5.263>\n",
      "    User 2 -> <1580:11.8904 1608:10.6388 1272:8.941 6:8.8667 608:8.5966 474:7.8094 349:7.6324 1294:7.3601 1250:7.3164 1036:7.2757>\n",
      "    User 3 -> <589:11.2785 1198:10.0473 1196:10.0328 2916:8.7666 592:8.2189 1097:8.0374 1214:7.585 1:6.9953 2000:6.9443 2628:6.7364>\n",
      "    User 4 -> <260:11.4507 589:10.121 858:9.4916 2194:6.6433 1221:6.6335 1954:6.211 2000:5.5323 110:5.3544 1218:5.059 1222:4.877>\n",
      "Precision@10 = 0.23014900662251653\n",
      "Recall@10 = 0.17895309718471897\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Creating MF recommender\n",
      "Training MF --> Epochs: 150  Training error: 0.3256995382282104  Test metrics: Precision@10 = 0.277682119205298  Recall@10 = 0.19278349310683404   \u001b[94m[0:02:35]\u001b[0m                 \n",
      "\u001b[34m--> elapsed time: 0:02:35 <--\u001b[0m\n",
      "Testing MF (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <318:2.0987 593:1.8065 364:1.7532 588:1.7203 34:1.5234 919:1.4659 1704:1.3765 2716:1.2662 2081:1.2322 1022:1.2272>\n",
      "    User 2 -> <527:3.4947 1580:2.8516 318:2.8183 1704:2.2614 150:2.2047 733:2.1194 1608:2.0573 377:2.0076 912:1.9526 1961:1.7308>\n",
      "    User 3 -> <1198:1.8237 1196:1.4937 2918:1.3737 2791:1.3117 2716:1.3054 2028:1.2315 2804:1.115 2000:1.0812 1307:1.075 1:1.0626>\n",
      "    User 4 -> <260:2.6732 1291:1.5585 589:1.471 2571:1.3477 110:1.3121 1200:1.2999 858:1.1797 457:1.0829 2000:0.9017 1610:0.9005>\n",
      "Precision@10 = 0.27764900662251657\n",
      "Recall@10 = 0.1927300021391895\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "=========================\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6847/1864745669.py:15: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings_df = pd.read_csv(file, sep=sep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================\n",
      "Extra testing checking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6847/1864745669.py:15: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings_df = pd.read_csv(file, sep=sep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Creating item cosine similarity\n",
      "\u001b[34m--> elapsed time: 0:00:14 <--\u001b[0m\n",
      "Creating kNN recommender\n",
      "\u001b[34m--> elapsed time: 0:00:06 <--\u001b[0m\n",
      "Testing ItemKNNRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <364:13.6401 588:13.1319 2087:11.7567 1688:10.8046 2078:10.5542 2394:9.8696 593:9.1441 2716:8.9833 2080:8.789 1947:8.5721>\n",
      "    User 2 -> <1580:18.6165 110:16.529 377:15.9019 733:15.4245 260:14.7194 349:13.2815 1918:13.1735 1573:12.7744 3793:12.295 1608:11.9151>\n",
      "    User 3 -> <1291:11.7745 260:11.3979 2987:11.1844 2791:11.0182 2804:10.79 1:10.4432 2918:10.3757 1288:10.0501 1080:10.0132 1234:9.1186>\n",
      "    User 4 -> <1291:12.7522 1270:12.2498 589:10.3454 2571:10.3071 1197:9.7684 858:9.6686 1200:9.3625 2194:9.2543 1127:8.9986 541:8.0335>\n",
      "Precision@10 = 0.23639072847682122\n",
      "Recall@10 = 0.16278150258092822\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n",
      "-------------------------\n",
      "Creating user cosine similarity\n",
      "\u001b[34m--> elapsed time: 0:00:05 <--\u001b[0m\n",
      "Creating kNN average recommender\n",
      "\u001b[34m--> elapsed time: 0:07:45 <--\u001b[0m\n",
      "Testing NormalizedKNNRecommender (top 10)\n",
      "Four example recommendations:\n",
      "    User 1 -> <3114:5 34:4.5825 2080:4.4135 3396:4.3981 2396:4.2308 1097:4.1791 2078:4.1415 2096:4.135 588:4.1326 2081:3.965>\n",
      "    User 2 -> <527:5 110:5 318:4.7807 1704:4.4216 260:4.4108 1580:4.3927 1291:4.3766 474:4.3489 2763:4.1615 733:4.1577>\n",
      "    User 3 -> <260:4.8429 1240:4.8004 858:4.6577 1:4.3992 1291:4.3568 1265:4.2132 1214:4.1704 2918:4.0305 2174:3.8504 2628:3.813>\n",
      "    User 4 -> <1610:4.8245 589:4.6814 457:4.5363 2194:4.4413 1304:4.3947 2028:4.3734 110:4.3599 2571:4.2255 2944:4.1919 1291:4.1668>\n",
      "Precision@10 = 0.19061258278145699\n",
      "Recall@10 = 0.14101215340687984\n",
      "\u001b[34m--> elapsed time: 0:00:00 <--\u001b[0m\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime, time\n",
    "\n",
    "# Test data structures and algorithms on a dataset.\n",
    "def test(ratings_file, example_user, example_item, k, minr, dim, topn=np.inf, cutoff=np.inf, threshold=1, sep=','):\n",
    "    print(colored(f'Reading the data at ' + time.strftime('%X...'), 'blue'))\n",
    "    start = time.time()\n",
    "    ratings = Ratings(ratings_file, sep)\n",
    "    print(f'Ratings matrix takes {round(10 * ratings.matrix().nbytes / 1024 / 1024) / 10:,} MB in RAM')\n",
    "    timer(start)\n",
    "\n",
    "    # Test Ratings class on the dataset.\n",
    "    test_data(ratings, example_user, example_item)\n",
    "    \n",
    "    # Produce a rating split and test a set of recommenders. \n",
    "    train, test = ratings.random_split(0.8)\n",
    "    metrics = [Precision(test, cutoff=cutoff, threshold=threshold), Recall(test, cutoff=cutoff, threshold=threshold)]\n",
    "    run_recommenders(train, metrics, k, minr, dim, topn)\n",
    "\n",
    "# Test the rating data handling code (Ratings class).\n",
    "def test_data(ratings, example_user, example_item):\n",
    "    print('-------------------------\\nTesting the ratings data structures')\n",
    "    print(f'{ratings.nratings():,} ratings by {ratings.nusers():,} users on {ratings.nitems():,} items')\n",
    "    print(f'Ratings of user {example_user}: {ratings.user_ratings(example_user)}')\n",
    "    print(f'Ratings of item {example_item}: {ratings.item_ratings(example_item)}')\n",
    "\n",
    "# Run some recommenders on the some rating data as input - no evaluation.\n",
    "def run_recommenders(train, metrics, k, minr, dim, topn):\n",
    "    print('-------------------------')\n",
    "    start = time.time()\n",
    "    run_recommender(RandomRecommender(train), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    run_recommender(MajorityRecommender(train, threshold=4), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    run_recommender(AverageRecommender(train, minr), metrics, topn)\n",
    "    start = timer(start)\n",
    "    \n",
    "    print('-------------------------')\n",
    "    print('Creating user cosine similarity')\n",
    "    sim = CosineUserSimilarity(train)\n",
    "    start = timer(start)\n",
    "    print('Creating kNN recommender')\n",
    "    knn = UserKNNRecommender(train, sim, k)\n",
    "    start = timer(start)\n",
    "    run_recommender(knn, metrics, topn)\n",
    "    timer(start)\n",
    "\n",
    "        \n",
    "    print('-------------------------')\n",
    "    start = time.time()\n",
    "    print('Creating MF recommender')\n",
    "    mf = MF(train, dim=dim, lrate=.0005, nepochs=150, test_metrics=metrics)\n",
    "    start = timer(start)\n",
    "    run_recommender(mf, metrics, topn)\n",
    "    timer(start)\n",
    "\n",
    "# Run a recommender and evaluate a list of metrics on its output.\n",
    "def run_recommender(recommender, metrics, topn):\n",
    "    print(f'Testing {recommender} (top {topn})')\n",
    "    recommendation = recommender.recommend(topn)\n",
    "    print('Four example recommendations:\\n' + recommendation.display(4))\n",
    "    for metric in metrics:\n",
    "        print(metric, '=', metric.compute(recommendation))\n",
    "\n",
    "from termcolor import colored\n",
    "def timer(start):\n",
    "    print(colored(f'--> elapsed time: {datetime.timedelta(seconds=round(time.time() - start))} <--', 'blue'))\n",
    "    return time.time()\n",
    "    \n",
    "np.random.seed(0)\n",
    "print('=========================\\nTesting toy 1 dataset')\n",
    "test('data/toy1.csv', example_user='v', example_item='b', k=4, minr=2, dim=5, topn=4, cutoff=4)\n",
    "print('=========================\\nTesting toy 2 dataset')\n",
    "test('data/toy2.csv', example_user=1, example_item=2, k=4, minr=2, dim=5, topn=4, cutoff=4)\n",
    "print('=========================\\nTesting MovieLens \\'1 million\\' dataset')\n",
    "test('data/ratings-1m.dat', example_user=200, example_item=1000, k=10, minr=3, dim=20, topn=10, cutoff=10, threshold=4, sep='::')\n",
    "print('=========================\\nDone.')\n",
    "\n",
    "# Additional testing?\n",
    "student_test('data/ratings-1m.dat', sep='::', k=10, topn=10, threshold=4, cutoff=10, minr=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salida obtenida por el estudiante\n",
    "\n",
    "*(por hacer)*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Enunciado P2",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
